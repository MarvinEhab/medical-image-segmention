{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarvinEhab/medical-image-segmention/blob/main/medsam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Google Colab NIFTI Data Reader with MedSAM AI Segmentation\n",
        "# Using Segment Anything Model adapted for Medical Imaging\n",
        "\n",
        "# Install required packages\n",
        "!pip install nibabel matplotlib seaborn plotly\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install segment-anything\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install SimpleITK\n",
        "!pip install scikit-image\n",
        "!pip install opencv-python\n",
        "!pip install timm\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import SimpleITK as sitk\n",
        "from skimage import measure, morphology\n",
        "from skimage.segmentation import watershed\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import zoom, gaussian_filter\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Try to import SAM\n",
        "try:\n",
        "    from segment_anything import sam_model_registry, SamPredictor\n",
        "    SAM_AVAILABLE = True\n",
        "except:\n",
        "    print(\"SAM not available, will use traditional methods\")\n",
        "    SAM_AVAILABLE = False\n",
        "\n",
        "class MedSAMOrganSegmenter:\n",
        "    \"\"\"AI-powered organ segmentation using MedSAM (Medical Segment Anything Model)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        self.models = {}\n",
        "        self.predictor = None\n",
        "        self.organ_configs = {\n",
        "            'liver': {\n",
        "                'parts': ['parenchyma', 'vessels', 'lesions'],\n",
        "                'colors': ['Reds', 'Blues', 'Oranges'],\n",
        "                'thresholds': [0.3, 0.4, 0.5],\n",
        "                'prompt_boxes': [  # Relative coordinates (x1, y1, x2, y2) from 0 to 1\n",
        "                    (0.3, 0.3, 0.7, 0.7),\n",
        "                    (0.35, 0.35, 0.65, 0.65),\n",
        "                    (0.4, 0.4, 0.6, 0.6)\n",
        "                ]\n",
        "            },\n",
        "            'kidney': {\n",
        "                'parts': ['cortex', 'medulla', 'pelvis'],\n",
        "                'colors': ['Greens', 'Oranges', 'Purples'],\n",
        "                'thresholds': [0.35, 0.4, 0.45],\n",
        "                'prompt_boxes': [\n",
        "                    (0.25, 0.25, 0.75, 0.75),\n",
        "                    (0.35, 0.35, 0.65, 0.65),\n",
        "                    (0.4, 0.4, 0.6, 0.6)\n",
        "                ]\n",
        "            },\n",
        "            'heart': {\n",
        "                'parts': ['left_ventricle', 'right_ventricle', 'myocardium'],\n",
        "                'colors': ['Reds', 'Blues', 'RdPu'],\n",
        "                'thresholds': [0.25, 0.2, 0.55],\n",
        "                'prompt_boxes': [\n",
        "                    (0.3, 0.35, 0.55, 0.65),  # LV (left side)\n",
        "                    (0.45, 0.35, 0.7, 0.65),  # RV (right side)\n",
        "                    (0.25, 0.3, 0.75, 0.7)    # Myocardium (full heart)\n",
        "                ]\n",
        "            },\n",
        "            'brain': {\n",
        "                'parts': ['gray_matter', 'white_matter', 'csf'],\n",
        "                'colors': ['Greys', 'bone', 'Blues'],\n",
        "                'thresholds': [0.3, 0.3, 0.4],\n",
        "                'prompt_boxes': [\n",
        "                    (0.2, 0.2, 0.8, 0.8),\n",
        "                    (0.3, 0.3, 0.7, 0.7),\n",
        "                    (0.35, 0.35, 0.65, 0.65)\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def load_medsam_model(self, model_type='vit_b'):\n",
        "        \"\"\"\n",
        "        Load MedSAM (Segment Anything Model for Medical Imaging)\n",
        "        model_type: 'vit_b' (base), 'vit_l' (large), or 'vit_h' (huge)\n",
        "        \"\"\"\n",
        "        if not SAM_AVAILABLE:\n",
        "            print(\"SAM not available. Please install: pip install segment-anything\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            print(f\"Loading MedSAM model: {model_type}\")\n",
        "\n",
        "            # Download SAM checkpoint\n",
        "            checkpoint_urls = {\n",
        "                'vit_b': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth',\n",
        "                'vit_l': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth',\n",
        "                'vit_h': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
        "            }\n",
        "\n",
        "            checkpoint_path = f'sam_{model_type}.pth'\n",
        "\n",
        "            if not os.path.exists(checkpoint_path):\n",
        "                print(f\"Downloading {model_type} checkpoint...\")\n",
        "                import urllib.request\n",
        "                urllib.request.urlretrieve(checkpoint_urls[model_type], checkpoint_path)\n",
        "                print(\"Download complete!\")\n",
        "\n",
        "            # Load SAM model\n",
        "            sam = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
        "            sam = sam.to(self.device)\n",
        "            sam.eval()\n",
        "\n",
        "            # Create predictor\n",
        "            self.predictor = SamPredictor(sam)\n",
        "            self.models['medsam'] = sam\n",
        "\n",
        "            print(f\"MedSAM {model_type} loaded successfully!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading MedSAM: {str(e)}\")\n",
        "            print(\"Falling back to traditional methods\")\n",
        "            return False\n",
        "\n",
        "    def segment_with_medsam(self, data, organ_type='liver'):\n",
        "        \"\"\"Segment using MedSAM with prompt engineering\"\"\"\n",
        "        print(f\"Using MedSAM AI segmentation for {organ_type}\")\n",
        "\n",
        "        if self.predictor is None:\n",
        "            print(\"MedSAM not loaded. Loading now...\")\n",
        "            success = self.load_medsam_model('vit_b')\n",
        "            if not success:\n",
        "                return self.segment_with_traditional_methods(data, organ_type)\n",
        "\n",
        "        if len(data.shape) == 4:\n",
        "            data = data[:, :, :, 0]\n",
        "\n",
        "        original_shape = data.shape\n",
        "        segmentations = np.zeros((4,) + original_shape)\n",
        "\n",
        "        config = self.organ_configs[organ_type]\n",
        "        prompt_boxes = config['prompt_boxes']\n",
        "\n",
        "        # Normalize data\n",
        "        data_norm = (data - np.min(data)) / (np.max(data) - np.min(data) + 1e-8)\n",
        "\n",
        "        # Process key slices with MedSAM\n",
        "        print(\"   Processing slices with MedSAM...\")\n",
        "        mid_z = original_shape[2] // 2\n",
        "        key_slices = [\n",
        "            mid_z - 10, mid_z - 5, mid_z, mid_z + 5, mid_z + 10\n",
        "        ]\n",
        "        key_slices = [z for z in key_slices if 0 <= z < original_shape[2]]\n",
        "\n",
        "        slice_predictions = {i: [] for i in range(3)}\n",
        "\n",
        "        for z_idx in key_slices:\n",
        "            try:\n",
        "                # Extract slice\n",
        "                slice_2d = data_norm[:, :, z_idx]\n",
        "\n",
        "                # Convert to 3-channel RGB\n",
        "                slice_rgb = np.stack([slice_2d] * 3, axis=-1)\n",
        "                slice_rgb = (slice_rgb * 255).astype(np.uint8)\n",
        "\n",
        "                # Resize to optimal size for SAM (1024x1024)\n",
        "                h, w = slice_rgb.shape[:2]\n",
        "                target_size = 1024\n",
        "                scale = target_size / max(h, w)\n",
        "                new_h, new_w = int(h * scale), int(w * scale)\n",
        "                slice_resized = cv2.resize(slice_rgb, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                # Pad to square\n",
        "                slice_padded = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
        "                y_offset = (target_size - new_h) // 2\n",
        "                x_offset = (target_size - new_w) // 2\n",
        "                slice_padded[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = slice_resized\n",
        "\n",
        "                # Set image for SAM\n",
        "                self.predictor.set_image(slice_padded)\n",
        "\n",
        "                # Segment each part using prompt boxes\n",
        "                for part_idx, box_coords in enumerate(prompt_boxes[:3]):\n",
        "                    # Convert relative coordinates to absolute\n",
        "                    x1 = int(box_coords[0] * target_size)\n",
        "                    y1 = int(box_coords[1] * target_size)\n",
        "                    x2 = int(box_coords[2] * target_size)\n",
        "                    y2 = int(box_coords[3] * target_size)\n",
        "\n",
        "                    box = np.array([x1, y1, x2, y2])\n",
        "\n",
        "                    # Predict with SAM\n",
        "                    masks, scores, logits = self.predictor.predict(\n",
        "                        box=box,\n",
        "                        multimask_output=True\n",
        "                    )\n",
        "\n",
        "                    # Select best mask\n",
        "                    best_mask_idx = np.argmax(scores)\n",
        "                    mask = masks[best_mask_idx]\n",
        "\n",
        "                    # Extract relevant region and resize back\n",
        "                    mask_region = mask[y_offset:y_offset+new_h, x_offset:x_offset+new_w]\n",
        "                    mask_original = cv2.resize(\n",
        "                        mask_region.astype(np.uint8),\n",
        "                        (w, h),\n",
        "                        interpolation=cv2.INTER_LINEAR\n",
        "                    ).astype(np.float32)\n",
        "\n",
        "                    slice_predictions[part_idx].append((z_idx, mask_original))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   Error on slice {z_idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Combine SAM predictions with traditional methods\n",
        "        print(\"   Combining MedSAM with traditional segmentation...\")\n",
        "        traditional_seg = self.segment_with_traditional_methods(data, organ_type)\n",
        "\n",
        "        if any(slice_predictions.values()):\n",
        "            # Interpolate SAM predictions across volume\n",
        "            for part_idx in range(3):\n",
        "                predictions = slice_predictions[part_idx]\n",
        "                if predictions:\n",
        "                    # Fill in predicted slices\n",
        "                    for z_idx, mask in predictions:\n",
        "                        segmentations[part_idx+1, :, :, z_idx] = mask\n",
        "\n",
        "                    # Interpolate between slices\n",
        "                    predicted_slices = sorted([z for z, _ in predictions])\n",
        "                    for z in range(original_shape[2]):\n",
        "                        if segmentations[part_idx+1, :, :, z].sum() == 0:\n",
        "                            # Find nearest predicted slices\n",
        "                            distances = [abs(z - pz) for pz in predicted_slices]\n",
        "                            if distances:\n",
        "                                nearest_idx = np.argmin(distances)\n",
        "                                nearest_z = predicted_slices[nearest_idx]\n",
        "\n",
        "                                # Simple copy for now\n",
        "                                decay = np.exp(-distances[nearest_idx] / 5.0)\n",
        "                                segmentations[part_idx+1, :, :, z] = (\n",
        "                                    segmentations[part_idx+1, :, :, nearest_z] * decay\n",
        "                                )\n",
        "\n",
        "            # Blend SAM (70%) with traditional (30%) for robustness\n",
        "            alpha = 0.7\n",
        "            for i in range(1, 4):\n",
        "                segmentations[i] = alpha * segmentations[i] + (1 - alpha) * traditional_seg[i]\n",
        "        else:\n",
        "            # Use traditional if SAM failed\n",
        "            segmentations = traditional_seg\n",
        "\n",
        "        # Apply smoothing\n",
        "        print(\"   Applying final smoothing...\")\n",
        "        for i in range(1, 4):\n",
        "            segmentations[i] = gaussian_filter(segmentations[i], sigma=1.0)\n",
        "\n",
        "        # Normalize\n",
        "        segmentations[0] = 1.0 - np.sum(segmentations[1:], axis=0)\n",
        "        segmentations = np.clip(segmentations, 0, 1)\n",
        "\n",
        "        return segmentations\n",
        "\n",
        "    def segment_with_traditional_methods(self, data, organ_type='liver'):\n",
        "        \"\"\"Optimized segmentation with smooth upsampling\"\"\"\n",
        "        print(f\"Using traditional segmentation methods for {organ_type}\")\n",
        "\n",
        "        if len(data.shape) == 4:\n",
        "            data = data[:, :, :, 0]\n",
        "\n",
        "        original_shape = data.shape\n",
        "        if np.prod(data.shape) > 10**7:\n",
        "            print(\"   Downsampling large volume for faster processing...\")\n",
        "            downsample_factor = int(np.ceil((np.prod(data.shape) / 5**6)**(1/3)))\n",
        "            data_small = data[::downsample_factor, ::downsample_factor, ::downsample_factor]\n",
        "            print(f\"   Reduced from {original_shape} to {data_small.shape}\")\n",
        "        else:\n",
        "            data_small = data\n",
        "            downsample_factor = 1\n",
        "\n",
        "        data_small = data_small.astype(np.float32)\n",
        "        if np.max(data_small) > 0:\n",
        "            data_small = (data_small - np.min(data_small)) / (np.max(data_small) - np.min(data_small))\n",
        "\n",
        "        config = self.organ_configs.get(organ_type, self.organ_configs['liver'])\n",
        "        segmentations = np.zeros((4,) + data_small.shape)\n",
        "\n",
        "        print(\"   Applying intensity-based segmentation...\")\n",
        "\n",
        "        if organ_type == 'brain':\n",
        "            brain_mask = data_small > 0.1\n",
        "            gray_matter = (data_small > 0.4) & (data_small < 0.8) & brain_mask\n",
        "            segmentations[1] = gray_matter.astype(np.float32)\n",
        "            white_matter = (data_small > 0.6) & brain_mask\n",
        "            segmentations[2] = white_matter.astype(np.float32)\n",
        "            csf = (data_small > 0.1) & (data_small < 0.3) & brain_mask\n",
        "            segmentations[3] = csf.astype(np.float32)\n",
        "\n",
        "        elif organ_type == 'heart':\n",
        "            print(\"   Using specialized cardiac segmentation...\")\n",
        "            cardiac_mask = data_small > 0.2\n",
        "            blood_pool = (data_small > 0.15) & (data_small < 0.55) & cardiac_mask\n",
        "            blood_pool = morphology.binary_opening(blood_pool, morphology.ball(2))\n",
        "            blood_pool = morphology.binary_closing(blood_pool, morphology.ball(3))\n",
        "\n",
        "            labeled = measure.label(blood_pool)\n",
        "            regions = measure.regionprops(labeled)\n",
        "\n",
        "            if len(regions) >= 2:\n",
        "                regions_sorted = sorted(regions, key=lambda r: r.area, reverse=True)\n",
        "                lv_label = regions_sorted[0].label\n",
        "                lv_mask = (labeled == lv_label).astype(np.float32)\n",
        "                rv_label = regions_sorted[1].label\n",
        "                rv_mask = (labeled == rv_label).astype(np.float32)\n",
        "                lv_mask = morphology.binary_dilation(lv_mask, morphology.ball(1)).astype(np.float32)\n",
        "                rv_mask = morphology.binary_dilation(rv_mask, morphology.ball(1)).astype(np.float32)\n",
        "                segmentations[1] = lv_mask\n",
        "                segmentations[2] = rv_mask\n",
        "                print(f\"      - Found LV with {regions_sorted[0].area} voxels\")\n",
        "                print(f\"      - Found RV with {regions_sorted[1].area} voxels\")\n",
        "            elif len(regions) == 1:\n",
        "                print(\"      - Only one chamber detected, splitting spatially...\")\n",
        "                single_mask = blood_pool.astype(np.float32)\n",
        "                com = ndimage.center_of_mass(single_mask)\n",
        "                x_center = int(com[0])\n",
        "                lv_mask = single_mask.copy()\n",
        "                rv_mask = single_mask.copy()\n",
        "                lv_mask[x_center:, :, :] *= 0.3\n",
        "                rv_mask[:x_center, :, :] *= 0.3\n",
        "                segmentations[1] = lv_mask\n",
        "                segmentations[2] = rv_mask\n",
        "            else:\n",
        "                print(\"      - No distinct chambers found, using intensity thresholds...\")\n",
        "                segmentations[1] = ((data_small > 0.2) & (data_small < 0.5)).astype(np.float32)\n",
        "                segmentations[2] = ((data_small > 0.15) & (data_small < 0.35)).astype(np.float32)\n",
        "\n",
        "            myocardium = (data_small > 0.5) & cardiac_mask\n",
        "            myocardium = morphology.binary_opening(myocardium, morphology.ball(1))\n",
        "            myocardium = myocardium & ~(segmentations[1] > 0.3) & ~(segmentations[2] > 0.3)\n",
        "            segmentations[3] = myocardium.astype(np.float32)\n",
        "            print(f\"      - Myocardium segmented\")\n",
        "\n",
        "        else:\n",
        "            for i, threshold in enumerate(config['thresholds']):\n",
        "                mask = data_small > threshold\n",
        "                if mask.any():\n",
        "                    mask = morphology.binary_opening(mask, morphology.ball(1))\n",
        "                    mask = morphology.binary_closing(mask, morphology.ball(1))\n",
        "                segmentations[i+1] = mask.astype(np.float32)\n",
        "\n",
        "        if organ_type != 'brain' and organ_type != 'heart' and np.prod(data_small.shape) < 10**6:\n",
        "            print(\"   Applying watershed refinement...\")\n",
        "            try:\n",
        "                threshold = np.percentile(data_small[data_small > 0], 85)\n",
        "                markers = measure.label(data_small > threshold)\n",
        "                if np.max(markers) > 0 and np.max(markers) < 1000:\n",
        "                    watershed_result = watershed(-data_small, markers, mask=data_small > np.mean(data_small))\n",
        "                    unique_labels = np.unique(watershed_result)[1:]\n",
        "                    if len(unique_labels) > 3:\n",
        "                        for i in range(3):\n",
        "                            label_subset = unique_labels[i::3]\n",
        "                            for label in label_subset:\n",
        "                                mask = (watershed_result == label).astype(np.float32)\n",
        "                                segmentations[i+1] = np.maximum(segmentations[i+1], mask * 0.3)\n",
        "            except Exception as e:\n",
        "                print(f\"   Watershed skipped due to: {e}\")\n",
        "\n",
        "        for i in range(1, 4):\n",
        "            for j in range(i+1, 4):\n",
        "                overlap = segmentations[i] * segmentations[j]\n",
        "                segmentations[i] -= overlap * 0.5\n",
        "                segmentations[j] -= overlap * 0.5\n",
        "\n",
        "        segmentations[0] = 1.0 - np.sum(segmentations[1:], axis=0)\n",
        "        segmentations[0] = np.clip(segmentations[0], 0, 1)\n",
        "\n",
        "        if downsample_factor > 1:\n",
        "            print(\"   Upsampling with enhanced smooth interpolation...\")\n",
        "            segmentations_full = np.zeros((4,) + original_shape)\n",
        "            for i in range(4):\n",
        "                upsampled = zoom(segmentations[i], downsample_factor, order=3)\n",
        "                segmentations_full[i] = upsampled[:original_shape[0], :original_shape[1], :original_shape[2]]\n",
        "\n",
        "            print(\"   Applying multi-stage smoothing...\")\n",
        "            for i in range(1, 4):\n",
        "                segmentations_full[i] = gaussian_filter(segmentations_full[i], sigma=1.5)\n",
        "                if np.any(segmentations_full[i] > 0.3):\n",
        "                    binary_mask = segmentations_full[i] > 0.5\n",
        "                    smoothed_mask = morphology.binary_closing(binary_mask, morphology.ball(2))\n",
        "                    smoothed_mask = morphology.binary_opening(smoothed_mask, morphology.ball(1))\n",
        "                    segmentations_full[i] = 0.7 * segmentations_full[i] + 0.3 * smoothed_mask.astype(np.float32)\n",
        "                segmentations_full[i] = gaussian_filter(segmentations_full[i], sigma=0.5)\n",
        "\n",
        "            for i in range(4):\n",
        "                segmentations_full[i] = np.clip(segmentations_full[i], 0, 1)\n",
        "\n",
        "            return segmentations_full\n",
        "\n",
        "        return segmentations\n",
        "\n",
        "    def segment_organ(self, data, organ_type='liver', method='ai'):\n",
        "        \"\"\"Main segmentation function\"\"\"\n",
        "        print(f\"\\nStarting {organ_type} segmentation using {method} method...\")\n",
        "\n",
        "        if method == 'ai':\n",
        "            segmentation = self.segment_with_medsam(data, organ_type)\n",
        "        else:\n",
        "            segmentation = self.segment_with_traditional_methods(data, organ_type)\n",
        "\n",
        "        if segmentation is not None:\n",
        "            print(\"Segmentation completed successfully!\")\n",
        "            return segmentation\n",
        "        else:\n",
        "            print(\"Segmentation failed\")\n",
        "            return None\n",
        "\n",
        "    def visualize_segmentation(self, original_data, segmentation, organ_type='liver'):\n",
        "        \"\"\"Visualize the segmentation results\"\"\"\n",
        "        if segmentation is None:\n",
        "            print(\"No segmentation to visualize\")\n",
        "            return\n",
        "\n",
        "        config = self.organ_configs[organ_type]\n",
        "        parts = config['parts']\n",
        "        colors = config['colors']\n",
        "\n",
        "        if len(original_data.shape) == 4:\n",
        "            original_data = original_data[:, :, :, 0]\n",
        "\n",
        "        mid_z = original_data.shape[2] // 2\n",
        "\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle(f'{organ_type.title()} Segmentation Results (MedSAM)', fontsize=16, fontweight='bold')\n",
        "\n",
        "        axes[0, 0].imshow(original_data[:, :, mid_z].T, cmap='gray', origin='lower')\n",
        "        axes[0, 0].set_title('Original Image')\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        positions = [(0, 1), (0, 2), (1, 0)]\n",
        "\n",
        "        for i, (part, color) in enumerate(zip(parts, colors)):\n",
        "            if i < len(positions):\n",
        "                row, col = positions[i]\n",
        "                part_mask = segmentation[i+1, :, :, mid_z].T\n",
        "                axes[row, col].imshow(part_mask, cmap=color, origin='lower', alpha=0.8)\n",
        "                axes[row, col].imshow(original_data[:, :, mid_z].T, cmap='gray', origin='lower', alpha=0.3)\n",
        "                axes[row, col].set_title(f'{part.replace(\"_\", \" \").title()}')\n",
        "                axes[row, col].axis('off')\n",
        "\n",
        "        overlay = np.zeros((*original_data[:, :, mid_z].T.shape, 3))\n",
        "        base_img = original_data[:, :, mid_z].T\n",
        "        base_img_norm = (base_img - np.min(base_img)) / (np.max(base_img) - np.min(base_img))\n",
        "\n",
        "        rgb_colors = {\n",
        "            'Reds': [1, 0, 0], 'Blues': [0, 0, 1], 'Greens': [0, 1, 0],\n",
        "            'Oranges': [1, 0.5, 0], 'Purples': [0.5, 0, 1], 'RdPu': [1, 0, 0.5],\n",
        "            'Greys': [0.5, 0.5, 0.5], 'bone': [0.8, 0.8, 0.6]\n",
        "        }\n",
        "\n",
        "        for j, (part_name, part_color) in enumerate(zip(parts, colors)):\n",
        "            mask = segmentation[j+1, :, :, mid_z].T > 0.5\n",
        "            if part_color in rgb_colors:\n",
        "                color_rgb = rgb_colors[part_color]\n",
        "                overlay[mask, 0] = color_rgb[0]\n",
        "                overlay[mask, 1] = color_rgb[1]\n",
        "                overlay[mask, 2] = color_rgb[2]\n",
        "\n",
        "        alpha = 0.6\n",
        "        for c in range(3):\n",
        "            overlay[:, :, c] = alpha * overlay[:, :, c] + (1-alpha) * base_img_norm\n",
        "\n",
        "        axes[1, 1].imshow(overlay, origin='lower')\n",
        "        axes[1, 1].set_title('Combined Segmentation')\n",
        "        axes[1, 1].axis('off')\n",
        "        axes[1, 2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def generate_segmentation_stats(self, segmentation, organ_type='liver', voxel_size=(1.0, 1.0, 1.0)):\n",
        "        \"\"\"Generate statistics for the segmentation\"\"\"\n",
        "        if segmentation is None:\n",
        "            return\n",
        "\n",
        "        config = self.organ_configs[organ_type]\n",
        "        parts = config['parts']\n",
        "\n",
        "        print(f\"\\nSEGMENTATION STATISTICS - {organ_type.upper()}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        voxel_volume = np.prod(voxel_size)\n",
        "        total_volume = 0\n",
        "\n",
        "        for i, part in enumerate(parts):\n",
        "            mask = segmentation[i+1] > 0.5\n",
        "            volume_voxels = np.sum(mask)\n",
        "            volume_mm3 = volume_voxels * voxel_volume\n",
        "            volume_ml = volume_mm3 / 1000\n",
        "\n",
        "            print(f\"   {part.replace('_', ' ').title()}:\")\n",
        "            print(f\"     - Volume: {volume_ml:.2f} ml ({volume_voxels:,} voxels)\")\n",
        "            print(f\"     - Percentage: {(volume_voxels / segmentation[0].size) * 100:.2f}%\")\n",
        "            total_volume += volume_ml\n",
        "\n",
        "        print(f\"\\n   Total segmented volume: {total_volume:.2f} ml\")\n",
        "        print(f\"   Segmentation coverage: {(np.sum(segmentation[1:]) / segmentation[0].size) * 100:.2f}%\")\n",
        "\n",
        "    def compute_dice_coefficient(self, pred_mask, gt_mask, smooth=1e-6):\n",
        "        \"\"\"Compute Dice Coefficient\"\"\"\n",
        "        pred_flat = pred_mask.flatten()\n",
        "        gt_flat = gt_mask.flatten()\n",
        "        intersection = np.sum(pred_flat * gt_flat)\n",
        "        union = np.sum(pred_flat) + np.sum(gt_flat)\n",
        "        dice = (2.0 * intersection + smooth) / (union + smooth)\n",
        "        return dice\n",
        "\n",
        "    def compute_iou(self, pred_mask, gt_mask, smooth=1e-6):\n",
        "        \"\"\"Compute IoU (Jaccard Index)\"\"\"\n",
        "        pred_flat = pred_mask.flatten()\n",
        "        gt_flat = gt_mask.flatten()\n",
        "        intersection = np.sum(pred_flat * gt_flat)\n",
        "        union = np.sum(pred_flat) + np.sum(gt_flat) - intersection\n",
        "        iou = (intersection + smooth) / (union + smooth)\n",
        "        return iou\n",
        "\n",
        "    def compute_hausdorff_distance(self, pred_mask, gt_mask):\n",
        "        \"\"\"Compute Hausdorff Distance\"\"\"\n",
        "        from scipy.spatial.distance import directed_hausdorff\n",
        "        pred_boundary = pred_mask.astype(bool)\n",
        "        gt_boundary = gt_mask.astype(bool)\n",
        "        pred_coords = np.argwhere(pred_boundary)\n",
        "        gt_coords = np.argwhere(gt_boundary)\n",
        "\n",
        "        if len(pred_coords) == 0 or len(gt_coords) == 0:\n",
        "            return float('inf')\n",
        "\n",
        "        forward_hd = directed_hausdorff(pred_coords, gt_coords)[0]\n",
        "        backward_hd = directed_hausdorff(gt_coords, pred_coords)[0]\n",
        "        hausdorff_dist = max(forward_hd, backward_hd)\n",
        "        return hausdorff_dist\n",
        "\n",
        "    def evaluate_segmentation(self, pred_segmentation, gt_segmentation, organ_type='liver', voxel_size=(1.0, 1.0, 1.0)):\n",
        "        \"\"\"Evaluate segmentation quality\"\"\"\n",
        "        if pred_segmentation is None or gt_segmentation is None:\n",
        "            print(\"Error: Both predicted and ground truth segmentations required\")\n",
        "            return None\n",
        "\n",
        "        config = self.organ_configs[organ_type]\n",
        "        parts = config['parts']\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"SEGMENTATION EVALUATION METRICS - {organ_type.upper()}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for i, part in enumerate(parts):\n",
        "            print(f\"   {part.replace('_', ' ').title()}:\")\n",
        "            print(f\"   {'-'*40}\")\n",
        "\n",
        "            pred_mask = (pred_segmentation[i+1] > 0.5).astype(np.float32)\n",
        "            gt_mask = (gt_segmentation[i+1] > 0.5).astype(np.float32)\n",
        "\n",
        "            dice = self.compute_dice_coefficient(pred_mask, gt_mask)\n",
        "            iou = self.compute_iou(pred_mask, gt_mask)\n",
        "\n",
        "            try:\n",
        "                hd_voxels = self.compute_hausdorff_distance(pred_mask, gt_mask)\n",
        "                hd_mm = hd_voxels * np.mean(voxel_size)\n",
        "            except:\n",
        "                hd_voxels = float('inf')\n",
        "                hd_mm = float('inf')\n",
        "\n",
        "            results[part] = {\n",
        "                'dice': dice,\n",
        "                'iou': iou,\n",
        "                'hausdorff_distance_voxels': hd_voxels,\n",
        "                'hausdorff_distance_mm': hd_mm\n",
        "            }\n",
        "\n",
        "            print(f\"     • Dice Coefficient:        {dice:.4f}  {'✓ Excellent' if dice > 0.9 else '✓ Good' if dice > 0.7 else '⚠ Fair' if dice > 0.5 else '✗ Poor'}\")\n",
        "            print(f\"     • IoU (Jaccard Index):     {iou:.4f}  {'✓ Excellent' if iou > 0.8 else '✓ Good' if iou > 0.6 else '⚠ Fair' if iou > 0.4 else '✗ Poor'}\")\n",
        "\n",
        "            if hd_voxels != float('inf'):\n",
        "                print(f\"     • Hausdorff Distance:      {hd_mm:.2f} mm ({hd_voxels:.2f} voxels)\")\n",
        "                print(f\"                               {'✓ Excellent' if hd_mm < 2 else '✓ Good' if hd_mm < 5 else '⚠ Fair' if hd_mm < 10 else '✗ Poor'}\")\n",
        "            else:\n",
        "                print(f\"     • Hausdorff Distance:      N/A (no boundary detected)\")\n",
        "            print()\n",
        "\n",
        "        print(f\"   {'='*40}\")\n",
        "        print(f\"   OVERALL PERFORMANCE:\")\n",
        "        print(f\"   {'='*40}\")\n",
        "\n",
        "        avg_dice = np.mean([results[part]['dice'] for part in parts])\n",
        "        avg_iou = np.mean([results[part]['iou'] for part in parts])\n",
        "        valid_hd = [results[part]['hausdorff_distance_mm'] for part in parts\n",
        "                    if results[part]['hausdorff_distance_mm'] != float('inf')]\n",
        "        avg_hd = np.mean(valid_hd) if valid_hd else float('inf')\n",
        "\n",
        "        print(f\"     • Average Dice:            {avg_dice:.4f}\")\n",
        "        print(f\"     • Average IoU:             {avg_iou:.4f}\")\n",
        "        if avg_hd != float('inf'):\n",
        "            print(f\"     • Average Hausdorff Dist:  {avg_hd:.2f} mm\")\n",
        "\n",
        "        print(f\"\\n   {'='*40}\")\n",
        "        print(f\"   INTERPRETATION GUIDE:\")\n",
        "        print(f\"   {'='*40}\")\n",
        "        print(f\"     Dice & IoU:   >0.9 = Excellent | >0.7 = Good | >0.5 = Fair\")\n",
        "        print(f\"     Hausdorff:    <2mm = Excellent | <5mm = Good | <10mm = Fair\")\n",
        "        print(f\"   {'='*40}\\n\")\n",
        "\n",
        "        return results\n",
        "\n",
        "class NiftiReader:\n",
        "    \"\"\"Base NIFTI reader class\"\"\"\n",
        "    def __init__(self):\n",
        "        self.nifti_img = None\n",
        "        self.data = None\n",
        "        self.header = None\n",
        "        self.affine = None\n",
        "        self.filename = None\n",
        "\n",
        "    def upload_nifti_file(self):\n",
        "        \"\"\"Upload a NIFTI file\"\"\"\n",
        "        print(\"Select a NIFTI file (.nii or .nii.gz) to upload:\")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            filename = list(uploaded.keys())[0]\n",
        "            self.filename = filename\n",
        "            print(f\"Uploaded: {filename}\")\n",
        "            self.load_nifti_file(filename)\n",
        "        else:\n",
        "            print(\"No file uploaded\")\n",
        "\n",
        "    def load_sample_data(self):\n",
        "        \"\"\"Load sample brain data\"\"\"\n",
        "        print(\"Loading sample brain data...\")\n",
        "        try:\n",
        "            import subprocess\n",
        "            result = subprocess.run(['wget', '-O', 'sample_brain.nii.gz',\n",
        "                                   \"https://github.com/neurolabusc/niivue-images/raw/main/chris_t1.nii.gz\"],\n",
        "                                  capture_output=True, text=True)\n",
        "            if result.returncode == 0:\n",
        "                self.filename = 'sample_brain.nii.gz'\n",
        "                self.load_nifti_file('sample_brain.nii.gz')\n",
        "        except:\n",
        "            print(\"Could not download sample data\")\n",
        "\n",
        "    def load_cardiac_sample_data(self):\n",
        "        \"\"\"Load synthetic cardiac data\"\"\"\n",
        "        print(\"Loading sample cardiac MRI data...\")\n",
        "        try:\n",
        "            print(\"   Generating synthetic cardiac MRI data...\")\n",
        "            synthetic_heart = self.generate_synthetic_heart_data()\n",
        "            synthetic_img = nib.Nifti1Image(synthetic_heart, np.eye(4))\n",
        "            nib.save(synthetic_img, 'synthetic_heart.nii.gz')\n",
        "            self.filename = 'synthetic_heart.nii.gz'\n",
        "            self.load_nifti_file('synthetic_heart.nii.gz')\n",
        "            print(\"Synthetic cardiac data loaded!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load cardiac data: {e}\")\n",
        "\n",
        "    def generate_synthetic_heart_data(self):\n",
        "        \"\"\"Generate synthetic heart MRI data with better contrast\"\"\"\n",
        "        shape = (128, 128, 80)\n",
        "        data = np.zeros(shape, dtype=np.float32)\n",
        "        center = (64, 64, 40)\n",
        "\n",
        "        print(\"   Creating left ventricle...\")\n",
        "        lv_center = (center[0] - 12, center[1], center[2])\n",
        "        for z in range(shape[2]):\n",
        "            for y in range(shape[1]):\n",
        "                for x in range(shape[0]):\n",
        "                    dist_lv = np.sqrt((x - lv_center[0])**2 + (y - lv_center[1])**2 + ((z - lv_center[2])*1.5)**2)\n",
        "                    if dist_lv < 12:\n",
        "                        data[x, y, z] = 0.4\n",
        "                    elif dist_lv < 18:\n",
        "                        data[x, y, z] = 0.75\n",
        "\n",
        "        print(\"   Creating right ventricle...\")\n",
        "        rv_center = (center[0] + 18, center[1] + 8, center[2])\n",
        "        for z in range(shape[2]):\n",
        "            for y in range(shape[1]):\n",
        "                for x in range(shape[0]):\n",
        "                    dist_rv = np.sqrt((x - rv_center[0])**2 + (y - rv_center[1])**2 + ((z - rv_center[2])*1.5)**2)\n",
        "                    if dist_rv < 10:\n",
        "                        data[x, y, z] = max(data[x, y, z], 0.35)\n",
        "                    elif dist_rv < 15 and data[x, y, z] < 0.5:\n",
        "                        data[x, y, z] = 0.7\n",
        "\n",
        "        print(\"   Adding myocardial wall...\")\n",
        "        for z in range(20, 60):\n",
        "            for y in range(35, 90):\n",
        "                for x in range(40, 90):\n",
        "                    if data[x, y, z] < 0.3:\n",
        "                        dist_to_lv = np.sqrt((x - lv_center[0])**2 + (y - lv_center[1])**2)\n",
        "                        dist_to_rv = np.sqrt((x - rv_center[0])**2 + (y - rv_center[1])**2)\n",
        "                        if 18 < dist_to_lv < 28 or 15 < dist_to_rv < 22:\n",
        "                            data[x, y, z] = 0.65\n",
        "\n",
        "        noise = np.random.normal(0, 0.03, shape)\n",
        "        data = np.clip(data + noise, 0, 1)\n",
        "\n",
        "        for z in range(shape[2]):\n",
        "            slice_factor = 1.0 - abs(z - center[2]) / center[2] * 0.3\n",
        "            data[:, :, z] *= slice_factor\n",
        "\n",
        "        print(f\"   Synthetic heart data created: {shape}\")\n",
        "        print(f\"   Intensity range: {data.min():.3f} to {data.max():.3f}\")\n",
        "        print(f\"   Mean intensity: {data.mean():.3f}\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    def load_nifti_file(self, filename):\n",
        "        \"\"\"Load NIFTI file\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading NIFTI file: {filename}\")\n",
        "            self.nifti_img = nib.load(filename)\n",
        "            self.data = self.nifti_img.get_fdata()\n",
        "            self.header = self.nifti_img.header\n",
        "            self.affine = self.nifti_img.affine\n",
        "            print(\"NIFTI file loaded successfully!\")\n",
        "            self.analyze_nifti_data()\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading NIFTI file: {str(e)}\")\n",
        "\n",
        "    def analyze_nifti_data(self):\n",
        "        \"\"\"Analyze NIFTI data\"\"\"\n",
        "        if self.data is None:\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"NIFTI FILE ANALYSIS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"\\nFilename: {self.filename}\")\n",
        "        print(f\"Data shape: {self.data.shape}\")\n",
        "        print(f\"Data type: {self.data.dtype}\")\n",
        "        print(f\"Voxel size: {self.header.get_zooms()[:3]} mm\")\n",
        "        print(f\"Memory usage: {self.data.nbytes / (1024**2):.2f} MB\")\n",
        "\n",
        "class EnhancedNiftiReader(NiftiReader):\n",
        "    \"\"\"Enhanced NIFTI reader with MedSAM segmentation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.segmenter = MedSAMOrganSegmenter()\n",
        "        self.current_segmentation = None\n",
        "        self.current_organ_type = None\n",
        "        self.ground_truth_segmentation = None\n",
        "\n",
        "    def load_ground_truth(self, gt_filename):\n",
        "        \"\"\"Load ground truth segmentation for evaluation\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading ground truth: {gt_filename}\")\n",
        "            gt_img = nib.load(gt_filename)\n",
        "            gt_data = gt_img.get_fdata()\n",
        "\n",
        "            if len(gt_data.shape) == 3:\n",
        "                segmentation = np.zeros((4,) + gt_data.shape)\n",
        "                for i in range(4):\n",
        "                    segmentation[i] = (gt_data == i).astype(np.float32)\n",
        "                self.ground_truth_segmentation = segmentation\n",
        "            else:\n",
        "                self.ground_truth_segmentation = gt_data\n",
        "\n",
        "            print(\"Ground truth loaded successfully!\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading ground truth: {e}\")\n",
        "            return False\n",
        "\n",
        "    def evaluate_current_segmentation(self):\n",
        "        \"\"\"Evaluate current segmentation against ground truth\"\"\"\n",
        "        if self.current_segmentation is None:\n",
        "            print(\"No current segmentation to evaluate\")\n",
        "            return None\n",
        "\n",
        "        if self.ground_truth_segmentation is None:\n",
        "            print(\"No ground truth loaded. Use reader.load_ground_truth('filename.nii.gz')\")\n",
        "            return None\n",
        "\n",
        "        voxel_size = self.header.get_zooms()[:3] if self.header else (1.0, 1.0, 1.0)\n",
        "\n",
        "        return self.segmenter.evaluate_segmentation(\n",
        "            self.current_segmentation,\n",
        "            self.ground_truth_segmentation,\n",
        "            self.current_organ_type,\n",
        "            voxel_size\n",
        "        )\n",
        "\n",
        "    def compare_segmentations(self, seg1, seg2, organ_type='liver', labels=('Method 1', 'Method 2')):\n",
        "        \"\"\"Compare two different segmentation methods\"\"\"\n",
        "        voxel_size = self.header.get_zooms()[:3] if self.header else (1.0, 1.0, 1.0)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"COMPARING SEGMENTATION METHODS - {organ_type.upper()}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        print(f\"Method 1: {labels[0]}\")\n",
        "        print(f\"Method 2: {labels[1]}\\n\")\n",
        "\n",
        "        results = self.segmenter.evaluate_segmentation(seg1, seg2, organ_type, voxel_size)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def segment_organ_parts(self, organ_type='liver', method='ai', sam_model='vit_b'):\n",
        "        \"\"\"Segment organ into 3 parts using MedSAM AI\"\"\"\n",
        "        if self.data is None:\n",
        "            print(\"No data loaded\")\n",
        "            return None\n",
        "\n",
        "        if method == 'ai':\n",
        "            self.segmenter.load_medsam_model(sam_model)\n",
        "\n",
        "        segmentation = self.segmenter.segment_organ(self.data, organ_type, method)\n",
        "\n",
        "        if segmentation is not None:\n",
        "            self.current_segmentation = segmentation\n",
        "            self.current_organ_type = organ_type\n",
        "            self.segmenter.visualize_segmentation(self.data, segmentation, organ_type)\n",
        "            voxel_size = self.header.get_zooms()[:3] if self.header else (1.0, 1.0, 1.0)\n",
        "            self.segmenter.generate_segmentation_stats(segmentation, organ_type, voxel_size)\n",
        "            return segmentation\n",
        "\n",
        "        return None\n",
        "\n",
        "    def save_segmentation(self, output_prefix='segmentation', export_format='both'):\n",
        "        \"\"\"Save segmentation as NIFTI files\"\"\"\n",
        "        if self.current_segmentation is None:\n",
        "            print(\"No segmentation to save\")\n",
        "            return []\n",
        "\n",
        "        print(f\"Saving segmentation results...\")\n",
        "        affine = self.affine if self.affine is not None else np.eye(4)\n",
        "        config = self.segmenter.organ_configs[self.current_organ_type]\n",
        "        parts = config['parts']\n",
        "        saved_files = []\n",
        "\n",
        "        if export_format in ['masks', 'both']:\n",
        "            print(\"\\nSaving individual binary masks...\")\n",
        "            for i, part in enumerate(parts):\n",
        "                part_data = (self.current_segmentation[i+1] > 0.5).astype(np.uint8) * 255\n",
        "                part_data_oriented = np.transpose(part_data, (2, 1, 0))\n",
        "                part_img = nib.Nifti1Image(part_data_oriented, affine)\n",
        "                part_img.header.set_data_dtype(np.uint8)\n",
        "                filename = f\"{output_prefix}_{self.current_organ_type}_{part}_mask.nii.gz\"\n",
        "                nib.save(part_img, filename)\n",
        "                saved_files.append(filename)\n",
        "                print(f\"   Saved: {filename}\")\n",
        "\n",
        "        if export_format in ['labels', 'both']:\n",
        "            print(\"\\nSaving combined label map...\")\n",
        "            combined = np.argmax(self.current_segmentation, axis=0).astype(np.uint8)\n",
        "            combined_oriented = np.transpose(combined, (2, 1, 0))\n",
        "            combined_img = nib.Nifti1Image(combined_oriented, affine)\n",
        "            combined_img.header.set_data_dtype(np.uint8)\n",
        "            combined_filename = f\"{output_prefix}_{self.current_organ_type}_labels.nii.gz\"\n",
        "            nib.save(combined_img, combined_filename)\n",
        "            saved_files.append(combined_filename)\n",
        "            print(f\"   Saved: {combined_filename}\")\n",
        "\n",
        "        print(\"\\nSaving original image...\")\n",
        "        original_data = self.data[:, :, :, 0] if len(self.data.shape) == 4 else self.data\n",
        "        original_normalized = original_data.astype(np.float32)\n",
        "        if np.max(original_normalized) > 0:\n",
        "            original_normalized = (original_normalized - np.min(original_normalized)) / (np.max(original_normalized) - np.min(original_normalized))\n",
        "        original_uint16 = (original_normalized * 65535).astype(np.uint16)\n",
        "        original_oriented = np.transpose(original_uint16, (2, 1, 0))\n",
        "        original_img = nib.Nifti1Image(original_oriented, affine)\n",
        "        original_img.header.set_data_dtype(np.uint16)\n",
        "        original_filename = f\"{output_prefix}_{self.current_organ_type}_original.nii.gz\"\n",
        "        nib.save(original_img, original_filename)\n",
        "        saved_files.append(original_filename)\n",
        "        print(f\"   Saved: {original_filename}\")\n",
        "\n",
        "        print(f\"\\n3D VIEWER READY FILES:\")\n",
        "        for filename in saved_files:\n",
        "            print(f\"   {filename}\")\n",
        "\n",
        "        return saved_files\n",
        "\n",
        "# Initialize reader\n",
        "print(\"Enhanced NIFTI Data Reader with MedSAM AI Segmentation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "reader = EnhancedNiftiReader()\n",
        "\n",
        "print(\"\\nHOW TO USE:\")\n",
        "print(\"\\n1. Load Data:\")\n",
        "print(\"   reader.upload_nifti_file()\")\n",
        "print(\"   reader.load_sample_data()\")\n",
        "print(\"   reader.load_cardiac_sample_data()\")\n",
        "print(\"\\n2. Segment Organs with MedSAM AI:\")\n",
        "print(\"   reader.segment_organ_parts('brain', method='ai', sam_model='vit_b')\")\n",
        "print(\"   reader.segment_organ_parts('heart', method='ai')\")\n",
        "print(\"   reader.segment_organ_parts('liver', method='ai')\")\n",
        "print(\"   reader.segment_organ_parts('kidney', method='traditional')  # fallback\")\n",
        "print(\"\\n3. Available SAM Models:\")\n",
        "print(\"   - 'vit_b': ViT-B (Base) - Faster, ~375MB\")\n",
        "print(\"   - 'vit_l': ViT-L (Large) - Better accuracy, ~1.2GB\")\n",
        "print(\"   - 'vit_h': ViT-H (Huge) - Best accuracy, ~2.4GB\")\n",
        "print(\"\\n4. Evaluate Segmentation (requires ground truth):\")\n",
        "print(\"   reader.load_ground_truth('ground_truth.nii.gz')\")\n",
        "print(\"   results = reader.evaluate_current_segmentation()\")\n",
        "print(\"\\n5. Compare Two Methods:\")\n",
        "print(\"   seg1 = reader.segment_organ_parts('heart', method='ai')\")\n",
        "print(\"   seg2 = reader.segment_organ_parts('heart', method='traditional')\")\n",
        "print(\"   reader.compare_segmentations(seg1, seg2, 'heart', ('MedSAM', 'Traditional'))\")\n",
        "print(\"\\n6. Save Results:\")\n",
        "print(\"   reader.save_segmentation('my_segmentation')\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURES:\")\n",
        "print(\"  ✓ MedSAM (Segment Anything for Medical Imaging)\")\n",
        "print(\"  ✓ Prompt-based segmentation with bounding boxes\")\n",
        "print(\"  ✓ Multiple SAM model sizes (vit_b, vit_l, vit_h)\")\n",
        "print(\"  ✓ Enhanced cardiac segmentation with ventricle detection\")\n",
        "print(\"  ✓ Automatic fallback to traditional methods\")\n",
        "print(\"  ✓ Smooth upsampling and interpolation\")\n",
        "print(\"  ✓ GPU acceleration when available\")\n",
        "print(\"  ✓ Export to NIFTI format for 3D viewing\")\n",
        "print(\"  ✓ EVALUATION METRICS:\")\n",
        "print(\"    • Dice Coefficient (overlap accuracy)\")\n",
        "print(\"    • IoU/Jaccard Index (intersection over union)\")\n",
        "print(\"    • Hausdorff Distance (boundary accuracy)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n🎯 ABOUT MedSAM:\")\n",
        "print(\"MedSAM uses Meta's Segment Anything Model (SAM) adapted for medical\")\n",
        "print(\"imaging. It uses prompt engineering (bounding boxes) to segment specific\")\n",
        "print(\"anatomical structures with high precision. The model excels at finding\")\n",
        "print(\"exact boundaries and works well with various medical imaging modalities.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nReady for NIFTI analysis with MedSAM AI!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfTNvBO2Vthh",
        "outputId": "c304cbfb-4f78-4384-d283-4c7b5e1334a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from nibabel) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting segment-anything\n",
            "  Downloading segment_anything-1.0-py3-none-any.whl.metadata (487 bytes)\n",
            "Downloading segment_anything-1.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-hjcncy3i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-hjcncy3i\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting SimpleITK\n",
            "  Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.2 kB)\n",
            "Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.5.2\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.9.9)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.19)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.35.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.8.3)\n",
            "Enhanced NIFTI Data Reader with MedSAM AI Segmentation\n",
            "============================================================\n",
            "Using device: cpu\n",
            "\n",
            "HOW TO USE:\n",
            "\n",
            "1. Load Data:\n",
            "   reader.upload_nifti_file()\n",
            "   reader.load_sample_data()\n",
            "   reader.load_cardiac_sample_data()\n",
            "\n",
            "2. Segment Organs with MedSAM AI:\n",
            "   reader.segment_organ_parts('brain', method='ai', sam_model='vit_b')\n",
            "   reader.segment_organ_parts('heart', method='ai')\n",
            "   reader.segment_organ_parts('liver', method='ai')\n",
            "   reader.segment_organ_parts('kidney', method='traditional')  # fallback\n",
            "\n",
            "3. Available SAM Models:\n",
            "   - 'vit_b': ViT-B (Base) - Faster, ~375MB\n",
            "   - 'vit_l': ViT-L (Large) - Better accuracy, ~1.2GB\n",
            "   - 'vit_h': ViT-H (Huge) - Best accuracy, ~2.4GB\n",
            "\n",
            "4. Evaluate Segmentation (requires ground truth):\n",
            "   reader.load_ground_truth('ground_truth.nii.gz')\n",
            "   results = reader.evaluate_current_segmentation()\n",
            "\n",
            "5. Compare Two Methods:\n",
            "   seg1 = reader.segment_organ_parts('heart', method='ai')\n",
            "   seg2 = reader.segment_organ_parts('heart', method='traditional')\n",
            "   reader.compare_segmentations(seg1, seg2, 'heart', ('MedSAM', 'Traditional'))\n",
            "\n",
            "6. Save Results:\n",
            "   reader.save_segmentation('my_segmentation')\n",
            "\n",
            "============================================================\n",
            "FEATURES:\n",
            "  ✓ MedSAM (Segment Anything for Medical Imaging)\n",
            "  ✓ Prompt-based segmentation with bounding boxes\n",
            "  ✓ Multiple SAM model sizes (vit_b, vit_l, vit_h)\n",
            "  ✓ Enhanced cardiac segmentation with ventricle detection\n",
            "  ✓ Automatic fallback to traditional methods\n",
            "  ✓ Smooth upsampling and interpolation\n",
            "  ✓ GPU acceleration when available\n",
            "  ✓ Export to NIFTI format for 3D viewing\n",
            "  ✓ EVALUATION METRICS:\n",
            "    • Dice Coefficient (overlap accuracy)\n",
            "    • IoU/Jaccard Index (intersection over union)\n",
            "    • Hausdorff Distance (boundary accuracy)\n",
            "============================================================\n",
            "\n",
            "🎯 ABOUT MedSAM:\n",
            "MedSAM uses Meta's Segment Anything Model (SAM) adapted for medical\n",
            "imaging. It uses prompt engineering (bounding boxes) to segment specific\n",
            "anatomical structures with high precision. The model excels at finding\n",
            "exact boundaries and works well with various medical imaging modalities.\n",
            "============================================================\n",
            "\n",
            "Ready for NIFTI analysis with MedSAM AI!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}