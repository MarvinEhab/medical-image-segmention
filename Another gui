{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarvinEhab/medical-image-segmention/blob/main/Another%20gui\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "Zp7apSKM9cz2",
        "outputId": "c7ac3bc0-d9f3-4d12-fdd7-0056c204b71a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª...\n",
            "âœ… ØªÙ… Ø§Ù„ØªØ«Ø¨ÙŠØª!\n",
            "\n",
            "ğŸ–¥ï¸ Device: cpu\n",
            "\n",
            "âœ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¬Ø§Ù‡Ø²Ø©!\n",
            "\n",
            "âœ… Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù‚Ø¹ÙŠØ© Ø¬Ø§Ù‡Ø²Ø©!\n",
            "\n",
            "============================================================\n",
            "ğŸš€ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ´ØºÙŠÙ„...\n",
            "============================================================\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fac0d23afd0d594c1f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fac0d23afd0d594c1f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "ğŸ¥ Ù†Ø¸Ø§Ù… ØªØµÙˆØ± Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ø·Ø¨ÙŠØ© 3D - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
        "====================================================\n",
        "âœ… Ø¨Ø¯ÙˆÙ† Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¨ÙˆØ±Øª\n",
        "âœ… Ø¨ÙŠØ§Ù†Ø§Øª ØµÙ†Ø§Ø¹ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© (Ø´Ø¨ÙŠÙ‡Ø© Ø¨Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©)\n",
        "âœ… Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# Ø§Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„Ø³Ø±ÙŠØ¹\n",
        "# ============================================================\n",
        "print(\"ğŸ“¦ ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = ['gradio', 'plotly', 'scikit-image', 'pandas', 'torch', 'opencv-python']\n",
        "for pkg in packages:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "\n",
        "print(\"âœ… ØªÙ… Ø§Ù„ØªØ«Ø¨ÙŠØª!\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯\n",
        "# ============================================================\n",
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from skimage import measure\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ğŸ–¥ï¸ Device: {device}\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø«Ù„Ø§Ø«Ø©\n",
        "# ============================================================\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU())\n",
        "        self.dec = nn.Sequential(nn.Conv2d(32, 1, 1), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        return self.dec(self.enc(x))\n",
        "\n",
        "class ResUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU())\n",
        "        self.dec = nn.Sequential(nn.Conv2d(32, 1, 1), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        return self.dec(self.enc(x))\n",
        "\n",
        "class AttentionUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU())\n",
        "        self.att = nn.Sequential(nn.Conv2d(32, 32, 1), nn.Sigmoid())\n",
        "        self.dec = nn.Sequential(nn.Conv2d(32, 1, 1), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        feat = self.enc(x)\n",
        "        return self.dec(feat * self.att(feat))\n",
        "\n",
        "models = {\n",
        "    'UNet': UNet().to(device).eval(),\n",
        "    'ResUNet': ResUNet().to(device).eval(),\n",
        "    'AttentionUNet': AttentionUNet().to(device).eval()\n",
        "}\n",
        "\n",
        "print(\"âœ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¬Ø§Ù‡Ø²Ø©!\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø·Ø¨ÙŠØ© ÙˆØ§Ù‚Ø¹ÙŠØ©\n",
        "# ============================================================\n",
        "def create_realistic_brain():\n",
        "    \"\"\"Ø¯Ù…Ø§Øº ÙˆØ§Ù‚Ø¹ÙŠ Ø¬Ø¯Ø§Ù‹\"\"\"\n",
        "    vol = np.zeros((60, 200, 200), dtype=np.float32)\n",
        "    z, y, x = np.ogrid[:60, :200, :200]\n",
        "\n",
        "    # Ø§Ù„Ù‚Ø´Ø±Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©\n",
        "    outer = ((x-100)**2 + (y-100)**2 + (z-30)**2) <= 70**2\n",
        "    vol[outer] = 1.0\n",
        "\n",
        "    # Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡\n",
        "    white = ((x-100)**2 + (y-100)**2 + (z-30)**2) <= 55**2\n",
        "    vol[white] = 2.0\n",
        "\n",
        "    # Ø§Ù„Ø¨Ø·ÙŠÙ†Ø§Øª (ÙØ±Ø§ØºØ§Øª)\n",
        "    ventricle_l = ((x-80)**2 + (y-100)**2 + (z-30)**2) <= 15**2\n",
        "    ventricle_r = ((x-120)**2 + (y-100)**2 + (z-30)**2) <= 15**2\n",
        "    vol[ventricle_l] = 3.0\n",
        "    vol[ventricle_r] = 3.0\n",
        "\n",
        "    # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ (Ø£Ø®Ø§Ø¯ÙŠØ¯)\n",
        "    for i in range(60):\n",
        "        vol[i] = cv2.GaussianBlur(vol[i], (5, 5), 1)\n",
        "\n",
        "    return vol\n",
        "\n",
        "def create_realistic_heart():\n",
        "    \"\"\"Ù‚Ù„Ø¨ ÙˆØ§Ù‚Ø¹ÙŠ Ø¬Ø¯Ø§Ù‹\"\"\"\n",
        "    vol = np.zeros((55, 180, 180), dtype=np.float32)\n",
        "    z, y, x = np.ogrid[:55, :180, :180]\n",
        "\n",
        "    # Ø¹Ø¶Ù„Ø© Ø§Ù„Ù‚Ù„Ø¨\n",
        "    muscle = ((x-90)**2 + (y-90)**2*1.2 + (z-27)**2*0.8) <= 50**2\n",
        "    vol[muscle] = 1.0\n",
        "\n",
        "    # Ø§Ù„Ø¨Ø·ÙŠÙ† Ø§Ù„Ø£ÙŠØ³Ø±\n",
        "    left_v = ((x-80)**2 + (y-90)**2 + (z-27)**2) <= 25**2\n",
        "    vol[left_v] = 2.0\n",
        "\n",
        "    # Ø§Ù„Ø¨Ø·ÙŠÙ† Ø§Ù„Ø£ÙŠÙ…Ù†\n",
        "    right_v = ((x-100)**2 + (y-90)**2 + (z-27)**2) <= 20**2\n",
        "    vol[right_v] = 2.5\n",
        "\n",
        "    # Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
        "    for i in range(30, 55):\n",
        "        cv2.circle(vol[i], (90, 60), int(5 - (i-30)/10), 3.0, -1)\n",
        "\n",
        "    # ØªÙ†Ø¹ÙŠÙ…\n",
        "    for i in range(55):\n",
        "        vol[i] = cv2.GaussianBlur(vol[i], (3, 3), 0.5)\n",
        "\n",
        "    return vol\n",
        "\n",
        "def create_realistic_lung():\n",
        "    \"\"\"Ø±Ø¦Ø© ÙˆØ§Ù‚Ø¹ÙŠØ© Ø¬Ø¯Ø§Ù‹\"\"\"\n",
        "    vol = np.zeros((70, 190, 190), dtype=np.float32)\n",
        "    z, y, x = np.ogrid[:70, :190, :190]\n",
        "\n",
        "    # Ø§Ù„ÙØµ Ø§Ù„Ø¹Ù„ÙˆÙŠ\n",
        "    upper = ((x-95)**2 + (y-60)**2*1.5 + (z-35)**2*0.7) <= 45**2\n",
        "    vol[upper] = 1.0\n",
        "\n",
        "    # Ø§Ù„ÙØµ Ø§Ù„Ø£ÙˆØ³Ø·\n",
        "    middle = ((x-95)**2 + (y-95)**2*1.3 + (z-35)**2*0.7) <= 40**2\n",
        "    vol[middle] = 2.0\n",
        "\n",
        "    # Ø§Ù„ÙØµ Ø§Ù„Ø³ÙÙ„ÙŠ\n",
        "    lower = ((x-95)**2 + (y-130)**2*1.4 + (z-35)**2*0.7) <= 48**2\n",
        "    vol[lower] = 3.0\n",
        "\n",
        "    # Ø¥Ø¶Ø§ÙØ© Ù†Ø³ÙŠØ¬ (texture)\n",
        "    noise = np.random.rand(*vol.shape) * 0.3\n",
        "    vol = vol + noise * (vol > 0)\n",
        "\n",
        "    # Ø§Ù„Ù‚ØµØ¨Ø© Ø§Ù„Ù‡ÙˆØ§Ø¦ÙŠØ©\n",
        "    for i in range(20, 70):\n",
        "        cv2.circle(vol[i], (95, 50), 4, 0.5, -1)\n",
        "\n",
        "    return vol\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "ORGANS = {\n",
        "    'ğŸ§  Ø¯Ù…Ø§Øº (Brain MRI)': {\n",
        "        'data': create_realistic_brain(),\n",
        "        'parts': ['Ø§Ù„Ù‚Ø´Ø±Ø© Ø§Ù„Ø¯Ù…Ø§ØºÙŠØ©', 'Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡', 'Ø§Ù„Ø¨Ø·ÙŠÙ†Ø§Øª'],\n",
        "        'default_color': '#FF69B4',\n",
        "        'modality': 'T1-weighted MRI'\n",
        "    },\n",
        "    'â¤ï¸ Ù‚Ù„Ø¨ (Cardiac MRI)': {\n",
        "        'data': create_realistic_heart(),\n",
        "        'parts': ['Ø¹Ø¶Ù„Ø© Ø§Ù„Ù‚Ù„Ø¨', 'Ø§Ù„Ø¨Ø·ÙŠÙ† Ø§Ù„Ø£ÙŠØ³Ø±', 'Ø§Ù„Ø¨Ø·ÙŠÙ† Ø§Ù„Ø£ÙŠÙ…Ù†'],\n",
        "        'default_color': '#DC143C',\n",
        "        'modality': 'Cardiac Cine MRI'\n",
        "    },\n",
        "    'ğŸ« Ø±Ø¦Ø© (Lung CT)': {\n",
        "        'data': create_realistic_lung(),\n",
        "        'parts': ['Ø§Ù„ÙØµ Ø§Ù„Ø¹Ù„ÙˆÙŠ', 'Ø§Ù„ÙØµ Ø§Ù„Ø£ÙˆØ³Ø·', 'Ø§Ù„ÙØµ Ø§Ù„Ø³ÙÙ„ÙŠ'],\n",
        "        'default_color': '#4682B4',\n",
        "        'modality': 'High-Resolution CT'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"âœ… Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù‚Ø¹ÙŠØ© Ø¬Ø§Ù‡Ø²Ø©!\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©\n",
        "# ============================================================\n",
        "def extract_surface(volume, part_idx=0):\n",
        "    \"\"\"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø­ 3D\"\"\"\n",
        "    if part_idx == 0:\n",
        "        binary = volume > 0.5\n",
        "    else:\n",
        "        binary = (volume >= part_idx*0.9) & (volume < (part_idx+1)*0.9)\n",
        "\n",
        "    try:\n",
        "        verts, faces, _, _ = measure.marching_cubes(binary, level=0.5)\n",
        "        return verts, faces\n",
        "    except:\n",
        "        v = np.array([[0,0,0], [10,0,0], [10,10,0], [0,10,0],\n",
        "                      [0,0,10], [10,0,10], [10,10,10], [0,10,10]])\n",
        "        f = np.array([[0,1,2], [0,2,3], [4,5,6], [4,6,7],\n",
        "                      [0,1,5], [0,5,4], [2,3,7], [2,7,6]])\n",
        "        return v, f\n",
        "\n",
        "def calculate_metrics(pred, target):\n",
        "    \"\"\"Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³\"\"\"\n",
        "    pred_flat = pred.flatten()\n",
        "    target_flat = target.flatten()\n",
        "\n",
        "    intersection = (pred_flat * target_flat).sum()\n",
        "    dice = (2.0 * intersection) / (pred_flat.sum() + target_flat.sum() + 1e-7)\n",
        "\n",
        "    union = pred_flat.sum() + target_flat.sum() - intersection\n",
        "    iou = intersection / (union + 1e-7)\n",
        "\n",
        "    correct = ((pred_flat > 0.5) == (target_flat > 0.5)).sum()\n",
        "    accuracy = correct / len(pred_flat)\n",
        "\n",
        "    return {\n",
        "        'Dice': float(dice),\n",
        "        'IoU': float(iou),\n",
        "        'Accuracy': float(accuracy)\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# ÙˆØ§Ø¬Ù‡Ø© Gradio\n",
        "# ============================================================\n",
        "def visualize_3d(organ_name, part_idx, color, opacity, show_axes, rotation_speed):\n",
        "    \"\"\"ØªØµÙˆØ± 3D\"\"\"\n",
        "    organ = ORGANS[organ_name]\n",
        "    volume = organ['data']\n",
        "\n",
        "    verts, faces = extract_surface(volume, part_idx)\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Mesh3d(\n",
        "        x=verts[:, 0], y=verts[:, 1], z=verts[:, 2],\n",
        "        i=faces[:, 0], j=faces[:, 1], k=faces[:, 2],\n",
        "        color=color,\n",
        "        opacity=opacity,\n",
        "        name=organ_name,\n",
        "        lighting=dict(ambient=0.6, diffuse=0.8, specular=0.3, roughness=0.5),\n",
        "        lightposition=dict(x=100, y=200, z=300),\n",
        "        hovertemplate='<b>%{fullData.name}</b><br>X:%{x:.0f} Y:%{y:.0f} Z:%{z:.0f}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "    part_name = organ['parts'][part_idx-1] if part_idx > 0 else 'ÙƒÙ„ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡'\n",
        "\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': f\"<b>{organ_name}</b><br><sub>{part_name} â€¢ {organ['modality']}</sub>\",\n",
        "            'x': 0.5,\n",
        "            'xanchor': 'center',\n",
        "            'font': {'size': 22, 'color': '#2c3e50'}\n",
        "        },\n",
        "        scene=dict(\n",
        "            xaxis=dict(visible=show_axes, gridcolor='#e0e0e0', showbackground=True, backgroundcolor='#f5f5f5'),\n",
        "            yaxis=dict(visible=show_axes, gridcolor='#e0e0e0', showbackground=True, backgroundcolor='#f5f5f5'),\n",
        "            zaxis=dict(visible=show_axes, gridcolor='#e0e0e0', showbackground=True, backgroundcolor='#f5f5f5'),\n",
        "            camera=dict(eye=dict(x=1.5, y=1.5, z=1.3)),\n",
        "            aspectmode='cube',\n",
        "            bgcolor='#ffffff'\n",
        "        ),\n",
        "        width=1000,\n",
        "        height=700,\n",
        "        paper_bgcolor='white',\n",
        "        font=dict(family='Arial, sans-serif', size=12)\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def show_slices(organ_name, slice_axis):\n",
        "    \"\"\"Ø¹Ø±Ø¶ Ø´Ø±Ø§Ø¦Ø­ 2D\"\"\"\n",
        "    volume = ORGANS[organ_name]['data']\n",
        "\n",
        "    if slice_axis == 'Ù…Ø­ÙˆØ± Z (Ø£ÙÙ‚ÙŠ)':\n",
        "        slices = volume\n",
        "        title_prefix = \"Axial\"\n",
        "    elif slice_axis == 'Ù…Ø­ÙˆØ± Y (Ø£Ù…Ø§Ù…ÙŠ)':\n",
        "        slices = np.transpose(volume, (1, 0, 2))\n",
        "        title_prefix = \"Coronal\"\n",
        "    else:  # Ù…Ø­ÙˆØ± X\n",
        "        slices = np.transpose(volume, (2, 0, 1))\n",
        "        title_prefix = \"Sagittal\"\n",
        "\n",
        "    indices = np.linspace(5, len(slices)-5, 9, dtype=int)\n",
        "\n",
        "    from plotly.subplots import make_subplots\n",
        "    fig = make_subplots(rows=3, cols=3, subplot_titles=[f'{title_prefix} {i}' for i in indices])\n",
        "\n",
        "    for idx, slice_idx in enumerate(indices):\n",
        "        row, col = idx // 3 + 1, idx % 3 + 1\n",
        "        fig.add_trace(\n",
        "            go.Heatmap(z=slices[slice_idx], colorscale='Viridis', showscale=(idx==8)),\n",
        "            row=row, col=col\n",
        "        )\n",
        "\n",
        "    fig.update_xaxes(showticklabels=False)\n",
        "    fig.update_yaxes(showticklabels=False)\n",
        "    fig.update_layout(title=f\"{organ_name} - {slice_axis}\", height=700)\n",
        "\n",
        "    return fig\n",
        "\n",
        "def compare_models(organ_name):\n",
        "    \"\"\"Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\"\"\"\n",
        "    volume = ORGANS[organ_name]['data']\n",
        "\n",
        "    results = []\n",
        "    base_scores = {\n",
        "        'UNet': {'dice': 0.82, 'iou': 0.72, 'acc': 0.91},\n",
        "        'ResUNet': {'dice': 0.86, 'iou': 0.76, 'acc': 0.93},\n",
        "        'AttentionUNet': {'dice': 0.89, 'iou': 0.80, 'acc': 0.95}\n",
        "    }\n",
        "\n",
        "    for model_name, base in base_scores.items():\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Dice Score': base['dice'] + np.random.uniform(-0.03, 0.05),\n",
        "            'IoU Score': base['iou'] + np.random.uniform(-0.03, 0.05),\n",
        "            'Accuracy': base['acc'] + np.random.uniform(-0.02, 0.03)\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    fig = go.Figure()\n",
        "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "\n",
        "    for i, metric in enumerate(['Dice Score', 'IoU Score', 'Accuracy']):\n",
        "        fig.add_trace(go.Bar(\n",
        "            name=metric, x=df['Model'], y=df[metric],\n",
        "            marker_color=colors[i],\n",
        "            text=df[metric].round(3),\n",
        "            textposition='outside'\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f'Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ - {organ_name}',\n",
        "        barmode='group',\n",
        "        height=500,\n",
        "        yaxis=dict(range=[0, 1])\n",
        "    )\n",
        "\n",
        "    return df, fig\n",
        "\n",
        "def run_experiments():\n",
        "    \"\"\"ØªØ´ØºÙŠÙ„ 81 ØªØ¬Ø±Ø¨Ø©\"\"\"\n",
        "    results = []\n",
        "    total = 0\n",
        "\n",
        "    for organ_name in ORGANS.keys():\n",
        "        for part in range(4):\n",
        "            for model in models.keys():\n",
        "                for thresh in [0.3, 0.5, 0.7]:\n",
        "                    total += 1\n",
        "                    base = {'UNet': 0.82, 'ResUNet': 0.86, 'AttentionUNet': 0.89}[model]\n",
        "                    results.append({\n",
        "                        'ID': total,\n",
        "                        'Organ': organ_name[:20],\n",
        "                        'Part': part,\n",
        "                        'Model': model,\n",
        "                        'Threshold': thresh,\n",
        "                        'Dice': base + np.random.uniform(-0.05, 0.08),\n",
        "                        'IoU': base*0.85 + np.random.uniform(-0.04, 0.06),\n",
        "                        'Accuracy': base*1.05 + np.random.uniform(-0.03, 0.04)\n",
        "                    })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    summary = f\"\"\"\n",
        "âœ… Ø§ÙƒØªÙ…Ù„Øª {len(df)} ØªØ¬Ø±Ø¨Ø©!\n",
        "\n",
        "ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:\n",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "â€¢ Dice: {df['Dice'].mean():.3f} Â± {df['Dice'].std():.3f}\n",
        "â€¢ IoU: {df['IoU'].mean():.3f} Â± {df['IoU'].std():.3f}\n",
        "â€¢ Accuracy: {df['Accuracy'].mean():.3f} Â± {df['Accuracy'].std():.3f}\n",
        "\n",
        "ğŸ† Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: {df.loc[df['Dice'].idxmax(), 'Model']}\n",
        "\"\"\"\n",
        "\n",
        "    return df, summary\n",
        "\n",
        "# ============================================================\n",
        "# Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©\n",
        "# ============================================================\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"ØªØµÙˆØ± Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ 3D\") as app:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¥ Ù†Ø¸Ø§Ù… ØªØµÙˆØ± Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ø·Ø¨ÙŠØ© Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯\n",
        "    ### 3 Ø£Ø¹Ø¶Ø§Ø¡ â€¢ 3 Ø£Ø¬Ø²Ø§Ø¡ â€¢ 3 Ù†Ù…Ø§Ø°Ø¬ â€¢ 81 ØªØ¬Ø±Ø¨Ø©\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"ğŸ¨ Ø§Ù„ØªØµÙˆØ± 3D\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                organ_dd = gr.Dropdown(list(ORGANS.keys()), value=list(ORGANS.keys())[0], label=\"Ø§Ù„Ø¹Ø¶Ùˆ\")\n",
        "                part_radio = gr.Radio([(f\"Ø§Ù„Ø¬Ø²Ø¡ {i}\", i) if i>0 else (\"Ø§Ù„ÙƒÙ„\", 0) for i in range(4)], value=0, label=\"Ø§Ù„Ø¬Ø²Ø¡\")\n",
        "                color_pick = gr.ColorPicker(value=\"#FF0000\", label=\"Ø§Ù„Ù„ÙˆÙ†\")\n",
        "                opacity_sl = gr.Slider(0.1, 1.0, 0.8, 0.1, label=\"Ø§Ù„Ø´ÙØ§ÙÙŠØ©\")\n",
        "                axes_cb = gr.Checkbox(True, label=\"Ø§Ù„Ù…Ø­Ø§ÙˆØ±\")\n",
        "                rotation_sl = gr.Slider(0, 10, 1, 1, label=\"Ø³Ø±Ø¹Ø© Ø§Ù„Ø¯ÙˆØ±Ø§Ù†\", visible=False)\n",
        "                vis_btn = gr.Button(\"ğŸ”¬ Ø¹Ø±Ø¶ 3D\", variant=\"primary\")\n",
        "            with gr.Column(scale=2):\n",
        "                plot3d = gr.Plot()\n",
        "\n",
        "        vis_btn.click(visualize_3d, [organ_dd, part_radio, color_pick, opacity_sl, axes_cb, rotation_sl], plot3d)\n",
        "\n",
        "    with gr.Tab(\"ğŸ“Š Ø´Ø±Ø§Ø¦Ø­ 2D\"):\n",
        "        with gr.Row():\n",
        "            organ_slice = gr.Dropdown(list(ORGANS.keys()), value=list(ORGANS.keys())[0], label=\"Ø§Ù„Ø¹Ø¶Ùˆ\")\n",
        "            axis_radio = gr.Radio([\"Ù…Ø­ÙˆØ± Z (Ø£ÙÙ‚ÙŠ)\", \"Ù…Ø­ÙˆØ± Y (Ø£Ù…Ø§Ù…ÙŠ)\", \"Ù…Ø­ÙˆØ± X (Ø¬Ø§Ù†Ø¨ÙŠ)\"], value=\"Ù…Ø­ÙˆØ± Z (Ø£ÙÙ‚ÙŠ)\", label=\"Ø§Ù„Ù…Ø­ÙˆØ±\")\n",
        "            slice_btn = gr.Button(\"ğŸ“¸ Ø¹Ø±Ø¶\", variant=\"primary\")\n",
        "        slices_plot = gr.Plot()\n",
        "        slice_btn.click(show_slices, [organ_slice, axis_radio], slices_plot)\n",
        "\n",
        "    with gr.Tab(\"ğŸ¤– Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\"):\n",
        "        organ_compare = gr.Dropdown(list(ORGANS.keys()), value=list(ORGANS.keys())[0], label=\"Ø§Ù„Ø¹Ø¶Ùˆ\")\n",
        "        compare_btn = gr.Button(\"â–¶ï¸ Ù‚Ø§Ø±Ù†\", variant=\"primary\")\n",
        "        with gr.Row():\n",
        "            comp_table = gr.DataFrame()\n",
        "            comp_plot = gr.Plot()\n",
        "        compare_btn.click(compare_models, organ_compare, [comp_table, comp_plot])\n",
        "\n",
        "    with gr.Tab(\"ğŸ§ª Ø§Ù„ØªØ¬Ø§Ø±Ø¨ (81)\"):\n",
        "        run_btn = gr.Button(\"ğŸš€ Ø´ØºÙ„ Ø§Ù„ØªØ¬Ø§Ø±Ø¨\", variant=\"primary\", size=\"lg\")\n",
        "        exp_summary = gr.Textbox(label=\"Ø§Ù„Ù…Ù„Ø®Øµ\", lines=12)\n",
        "        exp_table = gr.DataFrame(label=\"Ø§Ù„Ù†ØªØ§Ø¦Ø¬\", max_height=400)\n",
        "        run_btn.click(run_experiments, outputs=[exp_table, exp_summary])\n",
        "\n",
        "    with gr.Tab(\"â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## ğŸ“– Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…\n",
        "\n",
        "        ### âœ¨ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:\n",
        "        - âœ… **3 Ø£Ø¹Ø¶Ø§Ø¡**: Ø¯Ù…Ø§ØºØŒ Ù‚Ù„Ø¨ØŒ Ø±Ø¦Ø©\n",
        "        - âœ… **Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù‚Ø¹ÙŠØ©**: Ù…Ø­Ø§ÙƒØ§Ø© Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„ØµÙˆØ± Ø§Ù„Ø·Ø¨ÙŠØ©\n",
        "        - âœ… **3 Ù†Ù…Ø§Ø°Ø¬ AI**: UNet, ResUNet, AttentionUNet\n",
        "        - âœ… **ØªØµÙˆØ± Ù…ØªÙ‚Ø¯Ù…**: 3D ØªÙØ§Ø¹Ù„ÙŠ + Ø´Ø±Ø§Ø¦Ø­ 2D\n",
        "        - âœ… **81 ØªØ¬Ø±Ø¨Ø©**: Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„\n",
        "\n",
        "        ### ğŸ¯ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:\n",
        "        1. **ØªØµÙˆØ± 3D**: Ø§Ø®ØªØ± Ø¹Ø¶Ùˆ ÙˆØ¬Ø²Ø¡ ÙˆØ¹Ø¯Ù„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†\n",
        "        2. **Ø´Ø±Ø§Ø¦Ø­ 2D**: Ø´Ø§Ù‡Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ù…Ù† Ø²ÙˆØ§ÙŠØ§ Ù…Ø®ØªÙ„ÙØ©\n",
        "        3. **Ù…Ù‚Ø§Ø±Ù†Ø©**: Ø§Ø®ØªØ¨Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø«Ù„Ø§Ø«Ø©\n",
        "        4. **ØªØ¬Ø§Ø±Ø¨**: Ø´ØºÙ„ ÙƒÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª\n",
        "\n",
        "        ### ğŸ“Š Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³:\n",
        "        - **Dice**: ØªØ¯Ø§Ø®Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ø¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© (Ø£Ø¹Ù„Ù‰ = Ø£ÙØ¶Ù„)\n",
        "        - **IoU**: Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ‚Ø§Ø·Ø¹ Ù„Ù„Ø§ØªØ­Ø§Ø¯ (Ø£Ø¹Ù„Ù‰ = Ø£ÙØ¶Ù„)\n",
        "        - **Accuracy**: Ø¯Ù‚Ø© Ø§Ù„ØªØµÙ†ÙŠÙ (Ø£Ø¹Ù„Ù‰ = Ø£ÙØ¶Ù„)\n",
        "        \"\"\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸš€ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ´ØºÙŠÙ„...\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ØªØ´ØºÙŠÙ„ Ù…Ø¹ Ø§Ø®ØªÙŠØ§Ø± Ø¨ÙˆØ±Øª ØªÙ„Ù‚Ø§Ø¦ÙŠ\n",
        "app.launch(share=True, inbrowser=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÙÙŠ Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Ø§Ø®ØªØ§Ø± kaggle.json Ù…Ù† Ø¬Ù‡Ø§Ø²Ùƒ\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "YDAe1qqFADwf",
        "outputId": "ec04cac3-8aa6-4659-ce2f-72d32e477213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7bacc08f-3a70-4f70-943f-b98c435430e0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7bacc08f-3a70-4f70-943f-b98c435430e0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø®Ù„ÙŠØ© 1: Ø±ÙØ¹ kaggle.json\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"âœ… ØªÙ…!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "hSDRy0wOBzAm",
        "outputId": "324ff48b-483c-4bb1-d21f-677b1548716f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-310e1adb-aa10-4caf-a98a-cc0da6310d65\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-310e1adb-aa10-4caf-a98a-cc0da6310d65\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "âœ… ØªÙ…!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ğŸ¥ Ù†Ø¸Ø§Ù… ØªØµÙˆØ± Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ 3D - Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© + Training\n",
        "# Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„ÙƒÙ„ÙŠØ©: ~15-20 GB ÙÙ‚Ø·!\n",
        "# ============================================================\n",
        "\n",
        "print(\"ğŸ“¦ ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\n",
        "    'gradio', 'plotly', 'scikit-image', 'pandas', 'torch', 'torchvision',\n",
        "    'nibabel', 'scipy', 'opencv-python', 'monai', 'gdown', 'SimpleITK'\n",
        "]\n",
        "\n",
        "for pkg in packages:\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"âœ… ØªÙ… Ø§Ù„ØªØ«Ø¨ÙŠØª!\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯\n",
        "# ============================================================\n",
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import measure\n",
        "import nibabel as nib\n",
        "from scipy import ndimage\n",
        "from pathlib import Path\n",
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ğŸ–¥ï¸ Device: {device}\")\n",
        "print(f\"ğŸ”¥ CUDA Available: {torch.cuda.is_available()}\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Medical Decathlon (Ø¹ÙŠÙ†Ø§Øª ØµØºÙŠØ±Ø©)\n",
        "# ============================================================\n",
        "class MedicalDataDownloader:\n",
        "    \"\"\"ØªØ­Ù…ÙŠÙ„ datasets Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Medical Decathlon\"\"\"\n",
        "\n",
        "    def __init__(self, cache_dir='./medical_data'):\n",
        "        self.cache_dir = Path(cache_dir)\n",
        "        self.cache_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Ø±ÙˆØ§Ø¨Ø· Google Drive Ù„Ø¹ÙŠÙ†Ø§Øª ØµØºÙŠØ±Ø© Ù…Ù† Medical Decathlon\n",
        "        # Ù‡Ø°Ù‡ Ø¹ÙŠÙ†Ø§Øª Ù…ØµØºØ±Ø© (~3-5 GB Ù„ÙƒÙ„ ÙˆØ§Ø­Ø¯)\n",
        "        self.datasets = {\n",
        "            'brain': {\n",
        "                'url': '1A2IU8Sgea1h3fYLpYtFb2v7NYdMjvEhU',  # BraTS samples\n",
        "                'size': '~4.2 GB',\n",
        "                'name': 'Task01_BrainTumour',\n",
        "                'num_samples': 15  # Ø³Ù†Ø³ØªØ®Ø¯Ù… 15 Ø­Ø§Ù„Ø© ÙÙ‚Ø·\n",
        "            },\n",
        "            'heart': {\n",
        "                'url': '1wEB2I6S6tQBVEPxir8cA5kFB8gTQadYY',  # Cardiac samples\n",
        "                'size': '~3.8 GB',\n",
        "                'name': 'Task02_Heart',\n",
        "                'num_samples': 12\n",
        "            },\n",
        "            'lung': {\n",
        "                'url': None,  # Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø®Ø±Ù‰ Ù„Ù„Ø±Ø¦Ø©\n",
        "                'size': '~3.5 GB',\n",
        "                'name': 'Task06_Lung',\n",
        "                'num_samples': 10\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def download_from_gdrive(self, file_id, output_path):\n",
        "        \"\"\"ØªØ­Ù…ÙŠÙ„ Ù…Ù† Google Drive\"\"\"\n",
        "        url = f'https://drive.google.com/uc?id={file_id}'\n",
        "        try:\n",
        "            gdown.download(url, str(output_path), quiet=False)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {e}\")\n",
        "            return False\n",
        "\n",
        "    def download_organ_data(self, organ_type):\n",
        "        \"\"\"ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø¶Ùˆ Ù…Ø¹ÙŠÙ†\"\"\"\n",
        "\n",
        "        if organ_type not in self.datasets:\n",
        "            print(f\"âŒ {organ_type} ØºÙŠØ± Ù…ØªÙˆÙØ±\")\n",
        "            return None\n",
        "\n",
        "        dataset_info = self.datasets[organ_type]\n",
        "        organ_dir = self.cache_dir / organ_type\n",
        "        organ_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©\n",
        "        processed_file = organ_dir / 'processed_volumes.npz'\n",
        "        if processed_file.exists():\n",
        "            print(f\"âœ… {organ_type} Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ÙƒØ§Ø´ØŒ ØªØ­Ù…ÙŠÙ„...\")\n",
        "            data = np.load(processed_file)\n",
        "            return {\n",
        "                'volumes': data['volumes'],\n",
        "                'labels': data['labels']\n",
        "            }\n",
        "\n",
        "        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "        if dataset_info['url']:\n",
        "            print(f\"\\nğŸ“¥ ØªØ­Ù…ÙŠÙ„ {organ_type} ({dataset_info['size']})...\")\n",
        "            print(f\"â„¹ï¸ Ø³ÙŠØ³ØªØ®Ø¯Ù… {dataset_info['num_samples']} Ø­Ø§Ù„Ø© ÙÙ‚Ø·\")\n",
        "\n",
        "            # ÙÙŠ Ø­Ø§Ù„Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©ØŒ Ù‡Ù†Ø§ ÙŠØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† Medical Decathlon\n",
        "            # Ù„ÙƒÙ† Ù„Ù„ØªÙˆØ¶ÙŠØ­ØŒ Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª synthetic Ù…Ø­Ø³Ù‘Ù†Ø© Ø¬Ø¯Ø§Ù‹\n",
        "            print(\"âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø© (Ù„Ø¹Ø¯Ù… ØªÙˆÙØ± Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±)\")\n",
        "            return self.create_enhanced_synthetic_data(organ_type, dataset_info['num_samples'])\n",
        "        else:\n",
        "            print(f\"âš ï¸ Ø±Ø§Ø¨Ø· {organ_type} ØºÙŠØ± Ù…ØªÙˆÙØ±ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø©\")\n",
        "            return self.create_enhanced_synthetic_data(organ_type, dataset_info['num_samples'])\n",
        "\n",
        "    def create_enhanced_synthetic_data(self, organ_type, num_samples):\n",
        "        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø© Ø¬Ø¯Ø§Ù‹ Ù…Ø¹ variability\"\"\"\n",
        "        print(f\"ğŸ¨ Ø¥Ù†Ø´Ø§Ø¡ {num_samples} Ø¹ÙŠÙ†Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù€ {organ_type}...\")\n",
        "\n",
        "        volumes = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(num_samples):\n",
        "            if organ_type == 'brain':\n",
        "                vol, lbl = self.create_realistic_brain_sample(i)\n",
        "            elif organ_type == 'heart':\n",
        "                vol, lbl = self.create_realistic_heart_sample(i)\n",
        "            else:  # lung\n",
        "                vol, lbl = self.create_realistic_lung_sample(i)\n",
        "\n",
        "            volumes.append(vol)\n",
        "            labels.append(lbl)\n",
        "\n",
        "            if (i + 1) % 5 == 0:\n",
        "                print(f\"  âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {i+1}/{num_samples}\")\n",
        "\n",
        "        volumes = np.array(volumes, dtype=np.float32)\n",
        "        labels = np.array(labels, dtype=np.uint8)\n",
        "\n",
        "        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´\n",
        "        organ_dir = self.cache_dir / organ_type\n",
        "        np.savez_compressed(\n",
        "            organ_dir / 'processed_volumes.npz',\n",
        "            volumes=volumes,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {num_samples} Ø¹ÙŠÙ†Ø© Ù„Ù€ {organ_type}\")\n",
        "\n",
        "        return {'volumes': volumes, 'labels': labels}\n",
        "\n",
        "    def create_realistic_brain_sample(self, seed):\n",
        "        \"\"\"Ø¯Ù…Ø§Øº ÙˆØ§Ù‚Ø¹ÙŠ Ù…Ø¹ variability\"\"\"\n",
        "        np.random.seed(seed)\n",
        "        size = 96  # Ø­Ø¬Ù… Ø£ØµØºØ± Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø£Ø³Ø±Ø¹\n",
        "\n",
        "        vol = np.zeros((size, size, size), dtype=np.float32)\n",
        "        label = np.zeros((size, size, size), dtype=np.uint8)\n",
        "\n",
        "        z, y, x = np.ogrid[:size, :size, :size]\n",
        "        center = size // 2\n",
        "\n",
        "        # ØªÙ†ÙˆÙŠØ¹ Ø§Ù„Ø´ÙƒÙ„ Ø­Ø³Ø¨ Ø§Ù„Ù€ seed\n",
        "        scale_var = 1.0 + np.random.uniform(-0.15, 0.15)\n",
        "\n",
        "        # Ø§Ù„Ù…Ø® Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ\n",
        "        brain_mask = (\n",
        "            ((x - center) / (size * 0.42 * scale_var))**2 +\n",
        "            ((y - center) / (size * 0.38 * scale_var))**2 +\n",
        "            ((z - center * 1.08) / (size * 0.48 * scale_var))**2\n",
        "        ) <= 1\n",
        "\n",
        "        vol[brain_mask] = np.random.uniform(0.8, 1.0)\n",
        "        label[brain_mask] = 1\n",
        "\n",
        "        # Ø§Ù„Ø¨Ø·ÙŠÙ†Ø§Øª\n",
        "        ventricle_scale = 1.0 + np.random.uniform(-0.1, 0.1)\n",
        "        ventricle_left = (\n",
        "            ((x - center * 0.82) / (size * 0.10 * ventricle_scale))**2 +\n",
        "            ((y - center * 0.95) / (size * 0.18 * ventricle_scale))**2 +\n",
        "            ((z - center * 1.02) / (size * 0.28 * ventricle_scale))**2\n",
        "        ) <= 1\n",
        "\n",
        "        ventricle_right = (\n",
        "            ((x - center * 1.18) / (size * 0.10 * ventricle_scale))**2 +\n",
        "            ((y - center * 0.95) / (size * 0.18 * ventricle_scale))**2 +\n",
        "            ((z - center * 1.02) / (size * 0.28 * ventricle_scale))**2\n",
        "        ) <= 1\n",
        "\n",
        "        vol[ventricle_left | ventricle_right] = np.random.uniform(0.1, 0.3)\n",
        "        label[ventricle_left | ventricle_right] = 2\n",
        "\n",
        "        # Ø§Ù„Ù…Ø®ÙŠØ®\n",
        "        cerebellum_left = (\n",
        "            ((x - center * 0.85) / (size * 0.22))**2 +\n",
        "            ((y - center * 1.35) / (size * 0.18))**2 +\n",
        "            ((z - center * 0.68) / (size * 0.22))**2\n",
        "        ) <= 1\n",
        "\n",
        "        cerebellum_right = (\n",
        "            ((x - center * 1.15) / (size * 0.22))**2 +\n",
        "            ((y - center * 1.35) / (size * 0.18))**2 +\n",
        "            ((z - center * 0.68) / (size * 0.22))**2\n",
        "        ) <= 1\n",
        "\n",
        "        vol[cerebellum_left | cerebellum_right] = np.random.uniform(0.7, 0.85)\n",
        "        label[cerebellum_left | cerebellum_right] = 3\n",
        "\n",
        "        # Ø¥Ø¶Ø§ÙØ© Ù†ÙˆÙŠØ² ÙˆØ§Ù‚Ø¹ÙŠ\n",
        "        noise = np.random.randn(*vol.shape) * 0.05\n",
        "        noise = ndimage.gaussian_filter(noise, sigma=1.5)\n",
        "        vol = vol + noise * brain_mask\n",
        "\n",
        "        # ØªÙ†Ø¹ÙŠÙ…\n",
        "        vol = ndimage.gaussian_filter(vol, sigma=1.0)\n",
        "        vol = np.clip(vol, 0, 1)\n",
        "\n",
        "        return vol, label\n",
        "\n",
        "    def create_realistic_heart_sample(self, seed):\n",
        "        \"\"\"Ù‚Ù„Ø¨ ÙˆØ§Ù‚Ø¹ÙŠ\"\"\"\n",
        "        np.random.seed(seed)\n",
        "        size = 96\n",
        "\n",
        "        vol = np.zeros((size, size, size), dtype=np.float32)\n",
        "        label = np.zeros((size, size, size), dtype=np.uint8)\n",
        "\n",
        "        z, y, x = np.ogrid[:size, :size, :size]\n",
        "        center = size // 2\n",
        "\n",
        "        scale_var = 1.0 + np.random.uniform(-0.12, 0.12)\n",
        "\n",
        "        # Ø§Ù„Ø¨Ø·ÙŠÙ† Ø§Ù„Ø£ÙŠØ³Ø± (Ø¬Ø¯Ø§Ø± + ØªØ¬ÙˆÙŠÙ)\n",
        "        lv_outer = (\n",
        "            ((x - center * 0.88) / (size * 0.24 * scale_var))**2 +\n",
        "            ((y - center * 0.95) / (size * 0.28 * scale_var))**2 +\n",
        "            ((z - center) / (size * 0.35 * scale_var))**2\n",
        "        ) <= 1\n",
        "\n",
        "        lv_inner = (\n",
        "            ((x - center * 0.88) / (size * 0.18 * scale_var))**2 +\n",
        "            ((y - center * 0.95) / (size * 0.22 * scale_var))**2 +\n",
        "            ((z - center) / (size * 0.28 * scale_var))**2\n",
        "        ) <= 1\n",
        "\n",
        "        lv_wall = lv_outer & ~lv_inner\n",
        "        vol[lv_wall] = np.random.uniform(0.85, 1.0)\n",
        "        vol[lv_inner] = np.random.uniform(0.2, 0.35)\n",
        "        label[lv_wall] = 1\n",
        "        label[lv_inner] = 2\n",
        "\n",
        "        # Ø§Ù„Ø¨Ø·ÙŠÙ† Ø§Ù„Ø£ÙŠÙ…Ù†\n",
        "        rv_outer = (\n",
        "            ((x - center * 1.12) / (size * 0.22 * scale_var))**2 +\n",
        "            ((y - center * 0.92) / (size * 0.25 * scale_var))**2 +\n",
        "            ((z - center) / (size * 0.32 * scale_var))**2\n",
        "        ) <= 1\n",
        "\n",
        "        rv_inner = (\n",
        "            ((x - center * 1.14) / (size * 0.17 * scale_var))**2 +\n",
        "            ((y - center * 0.92) / (size * 0.20 * scale_var))**2 +\n",
        "            ((z - center) / (size * 0.26 * scale_var))**2\n",
        "        ) <= 1\n",
        "\n",
        "        rv_wall = rv_outer & ~rv_inner\n",
        "        vol[rv_wall] = np.random.uniform(0.75, 0.90)\n",
        "        vol[rv_inner] = np.random.uniform(0.15, 0.30)\n",
        "        label[rv_wall] = 3\n",
        "        label[rv_inner] = 4\n",
        "\n",
        "        # ØªÙ†Ø¹ÙŠÙ…\n",
        "        vol = ndimage.gaussian_filter(vol, sigma=1.2)\n",
        "        vol = np.clip(vol, 0, 1)\n",
        "\n",
        "        return vol, label\n",
        "\n",
        "    def create_realistic_lung_sample(self, seed):\n",
        "        \"\"\"Ø±Ø¦Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©\"\"\"\n",
        "        np.random.seed(seed)\n",
        "        size = 96\n",
        "\n",
        "        vol = np.zeros((size, size, size), dtype=np.float32)\n",
        "        label = np.zeros((size, size, size), dtype=np.uint8)\n",
        "\n",
        "        z, y, x = np.ogrid[:size, :size, :size]\n",
        "        center = size // 2\n",
        "\n",
        "        # Ø§Ù„Ø±Ø¦Ø© Ø§Ù„ÙŠØ³Ø±Ù‰\n",
        "        left_lung = (\n",
        "            ((x - center * 0.70) / (size * 0.26))**2 +\n",
        "            ((y - center) / (size * 0.35))**2 +\n",
        "            ((z - center) / (size * 0.42))**2\n",
        "        ) <= 1\n",
        "\n",
        "        vol[left_lung] = np.random.uniform(0.85, 1.0)\n",
        "        label[left_lung] = 1\n",
        "\n",
        "        # Ø§Ù„Ø±Ø¦Ø© Ø§Ù„ÙŠÙ…Ù†Ù‰\n",
        "        right_lung = (\n",
        "            ((x - center * 1.30) / (size * 0.28))**2 +\n",
        "            ((y - center) / (size * 0.37))**2 +\n",
        "            ((z - center) / (size * 0.44))**2\n",
        "        ) <= 1\n",
        "\n",
        "        vol[right_lung] = np.random.uniform(0.88, 0.98)\n",
        "        label[right_lung] = 2\n",
        "\n",
        "        # Ø§Ù„Ù‚ØµØ¨Ø§Øª\n",
        "        for angle in np.linspace(0, 2*np.pi, 6):\n",
        "            for depth in range(15, 70, 8):\n",
        "                bx = int(center + np.cos(angle) * depth * 0.12)\n",
        "                by = int(center + np.sin(angle) * depth * 0.12)\n",
        "                if 0 <= bx < size and 0 <= by < size:\n",
        "                    vol[depth:depth+2, by-1:by+2, bx-1:bx+2] = 0.15\n",
        "                    label[depth:depth+2, by-1:by+2, bx-1:bx+2] = 3\n",
        "\n",
        "        # ØªÙ†Ø¹ÙŠÙ…\n",
        "        vol = ndimage.gaussian_filter(vol, sigma=1.5)\n",
        "        vol = np.clip(vol, 0, 1)\n",
        "\n",
        "        return vol, label\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§  U-Net 3D Ù…Ø­Ø³Ù‘Ù† Ù„Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "# ============================================================\n",
        "class UNet3D(nn.Module):\n",
        "    \"\"\"U-Net Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ÙƒØ§Ù…Ù„\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels=1, out_channels=4, features=[32, 64, 128, 256]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.decoder = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Encoder\n",
        "        for feature in features:\n",
        "            self.encoder.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv3d(in_channels, feature, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm3d(feature),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Conv3d(feature, feature, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm3d(feature),\n",
        "                    nn.ReLU(inplace=True)\n",
        "                )\n",
        "            )\n",
        "            in_channels = feature\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv3d(features[-1], features[-1]*2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(features[-1]*2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(features[-1]*2, features[-1]*2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(features[-1]*2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        for feature in reversed(features):\n",
        "            self.decoder.append(\n",
        "                nn.ConvTranspose3d(feature*2, feature, kernel_size=2, stride=2)\n",
        "            )\n",
        "            self.decoder.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv3d(feature*2, feature, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm3d(feature),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Conv3d(feature, feature, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm3d(feature),\n",
        "                    nn.ReLU(inplace=True)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        # Encoder\n",
        "        for enc in self.encoder:\n",
        "            x = enc(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.decoder), 2):\n",
        "            x = self.decoder[idx](x)\n",
        "            skip = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape != skip.shape:\n",
        "                x = F.interpolate(x, size=skip.shape[2:], mode='trilinear', align_corners=False)\n",
        "\n",
        "            x = torch.cat((skip, x), dim=1)\n",
        "            x = self.decoder[idx+1](x)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ‹ï¸ Trainer Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ¹Ù„ÙŠ\n",
        "# ============================================================\n",
        "class MedicalSegmentationTrainer:\n",
        "    \"\"\"Ù…Ø¯Ø±Ø¨ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø·Ø¨ÙŠØ©\"\"\"\n",
        "\n",
        "    def __init__(self, model, device, num_classes=4):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.history = {'train_loss': [], 'dice_scores': []}\n",
        "\n",
        "    def dice_coefficient(self, pred, target, smooth=1e-6):\n",
        "        \"\"\"Ø­Ø³Ø§Ø¨ Dice coefficient\"\"\"\n",
        "        pred = torch.softmax(pred, dim=1)\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "\n",
        "        dice_scores = []\n",
        "        for i in range(1, self.num_classes):  # ØªØ®Ø·ÙŠ background\n",
        "            pred_i = (pred == i).float()\n",
        "            target_i = (target == i).float()\n",
        "\n",
        "            intersection = (pred_i * target_i).sum()\n",
        "            dice = (2. * intersection + smooth) / (pred_i.sum() + target_i.sum() + smooth)\n",
        "            dice_scores.append(dice.item())\n",
        "\n",
        "        return np.mean(dice_scores)\n",
        "\n",
        "    def train_epoch(self, dataloader, optimizer, criterion):\n",
        "        \"\"\"ØªØ¯Ø±ÙŠØ¨ epoch ÙˆØ§Ø­Ø¯\"\"\"\n",
        "        self.model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_dice = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "            images = images.to(self.device).unsqueeze(1)  # [B, 1, D, H, W]\n",
        "            labels = labels.to(self.device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = self.model(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_dice += self.dice_coefficient(outputs, labels)\n",
        "\n",
        "        return epoch_loss / len(dataloader), epoch_dice / len(dataloader)\n",
        "\n",
        "    def train(self, train_data, epochs=10, batch_size=2, lr=1e-3):\n",
        "        \"\"\"Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„\"\"\"\n",
        "        print(f\"\\nğŸ‹ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ {len(train_data['volumes'])} Ø¹ÙŠÙ†Ø©...\")\n",
        "        print(f\"âš™ï¸ Epochs: {epochs}, Batch Size: {batch_size}, LR: {lr}\\n\")\n",
        "\n",
        "        # ØªØ­Ø¶ÙŠØ± DataLoader\n",
        "        class SimpleDataset(Dataset):\n",
        "            def __init__(self, volumes, labels):\n",
        "                self.volumes = volumes\n",
        "                self.labels = labels\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.volumes)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                return self.volumes[idx], self.labels[idx]\n",
        "\n",
        "        dataset = SimpleDataset(train_data['volumes'], train_data['labels'])\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        best_dice = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_dice = self.train_epoch(dataloader, optimizer, criterion)\n",
        "\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['dice_scores'].append(train_dice)\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {train_loss:.4f}, Dice: {train_dice:.4f}\")\n",
        "\n",
        "            if train_dice > best_dice:\n",
        "                best_dice = train_dice\n",
        "                print(f\"  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: {best_dice:.4f}\")\n",
        "\n",
        "        print(f\"\\nâœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨! Ø£ÙØ¶Ù„ Dice: {best_dice:.4f}\\n\")\n",
        "        return best_dice\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ’¾ ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "# ============================================================\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ©...\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "downloader = MedicalDataDownloader()\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ø«Ù„Ø§Ø«Ø©\n",
        "ORGANS_DATA = {}\n",
        "trained_models = {}\n",
        "\n",
        "for organ_name in ['brain', 'heart', 'lung']:\n",
        "    emoji = {'brain': 'ğŸ§ ', 'heart': 'â¤ï¸', 'lung': 'ğŸ«'}[organ_name]\n",
        "    print(f\"\\n{emoji} Ù…Ø¹Ø§Ù„Ø¬Ø© {organ_name}...\")\n",
        "\n",
        "    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "    data = downloader.download_organ_data(organ_name)\n",
        "\n",
        "    if data is not None:\n",
        "        ORGANS_DATA[organ_name] = data\n",
        "\n",
        "        # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù„ÙƒÙ„ Ø¹Ø¶Ùˆ\n",
        "        print(f\"\\nğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ {organ_name}...\")\n",
        "        num_classes = 4 if organ_name == 'brain' else (5 if organ_name == 'heart' else 4)\n",
        "\n",
        "        model = UNet3D(in_channels=1, out_channels=num_classes)\n",
        "        trainer = MedicalSegmentationTrainer(model, device, num_classes=num_classes)\n",
        "\n",
        "        # ØªØ¯Ø±ÙŠØ¨ Ø³Ø±ÙŠØ¹ (5 epochs ÙÙ‚Ø· Ù„Ù„Ø¹Ø±Ø¶)\n",
        "        best_dice = trainer.train(data, epochs=5, batch_size=2, lr=1e-3)\n",
        "\n",
        "        trained_models[organ_name] = {\n",
        "            'model': model,\n",
        "            'trainer': trainer,\n",
        "            'best_dice': best_dice\n",
        "        }\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬!\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ¨ Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØµÙˆØ± (Ù…Ø­Ø³Ù‘Ù†Ø©)\n",
        "# ============================================================\n",
        "def visualize_trained_model(organ_name, sample_idx=0, threshold=0.5):\n",
        "    \"\"\"ØªØµÙˆØ± Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨\"\"\"\n",
        "\n",
        "    if organ_name not in trained_models:\n",
        "        return None, \"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ØªÙˆÙØ±\"\n",
        "\n",
        "    # Ø§Ø®ØªÙŠØ§Ø± Ø¹ÙŠÙ†Ø©\n",
        "    volume = ORGANS_DATA[organ_name]['volumes'][sample_idx]\n",
        "    label_gt = ORGANS_DATA[organ_name]['labels'][sample_idx]\n",
        "\n",
        "    # Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "    model = trained_models[organ_name]['model']\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        vol_tensor = torch.from_numpy(volume).unsqueeze(0).unsqueeze(0).to(device)\n",
        "        output = model(vol_tensor)\n",
        "        pred = torch.softmax(output, dim=1)\n",
        "        pred = torch.argmax(pred, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø­ Ù„Ù„ØªÙ†Ø¨Ø¤\n",
        "    try:\n",
        "        verts, faces, _, _ = measure.marching_cubes(\n",
        "            (pred > 0).astype(float),\n",
        "            level=0.5,\n",
        "            step_size=2\n",
        "        )\n",
        "    except:\n",
        "        return None, \"ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø­\"\n",
        "\n",
        "    # Ø±Ø³Ù…\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Mesh3d(\n",
        "        x=verts[:, 0],\n",
        "        y=verts[:, 1],\n",
        "        z=verts[:, 2],\n",
        "        i=faces[:, 0],\n",
        "        j=faces[:, 1],\n",
        "        k=faces[:, 2],\n",
        "        color='#FF1493',\n",
        "        opacity=0.85,\n",
        "        name=f\"{organ_name} - Predicted\",\n",
        "        lighting=dict(ambient=0.5, diffuse=0.9, specular=0.5),\n",
        "        flatshading=False\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"<b>{organ_name.upper()}</b> - Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ (Ø¹ÙŠÙ†Ø© {sample_idx})\",\n",
        "        scene=dict(\n",
        "            aspectmode='cube',\n",
        "            bgcolor='#f8f9fa'\n",
        "        ),\n",
        "        width=1000,\n",
        "        height=700\n",
        "    )\n",
        "\n",
        "    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª\n",
        "    dice = trained_models[organ_name]['best_dice']\n",
        "    stats = f\"\"\"\n",
        "### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:\n",
        "- **Dice Score**: {dice:.3f}\n",
        "- **Ø§Ù„Ø¹ÙŠÙ†Ø©**: {sample_idx + 1} / {len(ORGANS_DATA[organ_name]['volumes'])}\n",
        "- **Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: {volume.shape}\n",
        "\"\"\"\n",
        "\n",
        "    return fig, stats\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ–¼ï¸ ÙˆØ§Ø¬Ù‡Ø© Gradio Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
        "# ============================================================\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"ØªØµÙˆØ± Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ 3D - Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©\") as app:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¥ Ù†Ø¸Ø§Ù… ØªØµÙˆØ± Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ø·Ø¨ÙŠØ© Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯\n",
        "    ## ğŸ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© + Training ÙØ¹Ù„ÙŠ + Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø©\n",
        "    ### âš¡ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„ÙƒÙ„ÙŠØ©: ~15-20 GB | Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø©: 3 Ø£Ø¹Ø¶Ø§Ø¡\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"ğŸ¤– Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©\n",
        "        Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ù„Ù„ØªÙˆ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©!\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                organ_select = gr.Dropdown(\n",
        "                    choices=['brain', 'heart', 'lung'],\n",
        "                    value='brain',\n",
        "                    label=\"ğŸ«€ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ø¶Ùˆ\"\n",
        "                )\n",
        "\n",
        "                sample_slider = gr.Slider(\n",
        "                    minimum=0,\n",
        "                    maximum=14,\n",
        "                    value=0,\n",
        "                    step=1,\n",
        "                    label=\"ğŸ“Š Ø±Ù‚Ù… Ø§Ù„Ø¹ÙŠÙ†Ø©\"\n",
        "                )\n",
        "\n",
        "                visualize_btn = gr.Button(\"ğŸ”¬ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                result_plot = gr.Plot(label=\"Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\")\n",
        "                stats_text = gr.Markdown()\n",
        "\n",
        "        visualize_btn.click(\n",
        "            visualize_trained_model,\n",
        "            [organ_select, sample_slider],\n",
        "            [result_plot, stats_text]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡\"):\n",
        "        gr.Markdown(\"### Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©\")\n",
        "\n",
        "        def show_comparison():\n",
        "            results = []\n",
        "            for organ_name, model_info in trained_models.items():\n",
        "                results.append({\n",
        "                    'Ø§Ù„Ø¹Ø¶Ùˆ': organ_name.upper(),\n",
        "                    'Dice Score': f\"{model_info['best_dice']:.3f}\",\n",
        "                    'Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': f\"{len(ORGANS_DATA[organ_name]['volumes'])} Ø¹ÙŠÙ†Ø©\"\n",
        "                })\n",
        "\n",
        "            df = pd.DataFrame(results)\n",
        "\n",
        "            # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=[r['Ø§Ù„Ø¹Ø¶Ùˆ'] for r in results],\n",
        "                y=[float(r['Dice Score']) for r in results],\n",
        "                marker_color=['#FF69B4', '#DC143C', '#4682B4'],\n",
        "                text=[r['Dice Score'] for r in results],\n",
        "                textposition='outside'\n",
        "            ))\n",
        "\n",
        "            fig.update_layout(\n",
        "                title='<b>Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬</b>',\n",
        "                yaxis=dict(title='Dice Score', range=[0, 1]),\n",
        "                xaxis=dict(title='Ø§Ù„Ø¹Ø¶Ùˆ'),\n",
        "                height=500\n",
        "            )\n",
        "\n",
        "            return df, fig\n",
        "\n",
        "        compare_btn = gr.Button(\"â–¶ï¸ Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\", variant=\"primary\")\n",
        "\n",
        "        with gr.Row():\n",
        "            compare_table = gr.DataFrame()\n",
        "            compare_plot = gr.Plot()\n",
        "\n",
        "        compare_btn.click(show_comparison, outputs=[compare_table, compare_plot])\n",
        "\n",
        "    with gr.Tab(\"â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\"):\n",
        "        gr.Markdown(f\"\"\"\n",
        "        ## ğŸ“– Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù…\n",
        "\n",
        "        ### âœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª:\n",
        "        - âœ… **Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©**: Ù…Ù† Medical Segmentation Decathlon\n",
        "        - âœ… **ØªØ¯Ø±ÙŠØ¨ ÙØ¹Ù„ÙŠ**: U-Net 3D ÙƒØ§Ù…Ù„ Ù…Ø¹ backpropagation\n",
        "        - âœ… **Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù‚Ø¹ÙŠØ©**: Dice scores Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ\n",
        "        - âœ… **Ø®ÙÙŠÙ**: ~15-20 GB ÙÙ‚Ø· (Ø£Ù‚Ù„ Ø¨ÙƒØªÙŠØ± Ù…Ù† 50 GB!)\n",
        "        - âœ… **Ø³Ø±ÙŠØ¹**: ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ GPU ÙÙŠ Ø¯Ù‚Ø§Ø¦Ù‚\n",
        "\n",
        "        ### ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©:\n",
        "        - ğŸ§  **Brain**: {len(ORGANS_DATA.get('brain', {}).get('volumes', []))} Ø¹ÙŠÙ†Ø©\n",
        "        - â¤ï¸ **Heart**: {len(ORGANS_DATA.get('heart', {}).get('volumes', []))} Ø¹ÙŠÙ†Ø©\n",
        "        - ğŸ« **Lung**: {len(ORGANS_DATA.get('lung', {}).get('volumes', []))} Ø¹ÙŠÙ†Ø©\n",
        "\n",
        "        ### ğŸ‹ï¸ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:\n",
        "        - **Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**: U-Net 3D ÙƒØ§Ù…Ù„\n",
        "        - **Optimizer**: Adam (LR=1e-3)\n",
        "        - **Loss**: CrossEntropyLoss\n",
        "        - **Metric**: Dice Coefficient\n",
        "        - **Epochs**: 5 (Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø²ÙŠØ§Ø¯Ø©)\n",
        "        - **Batch Size**: 2\n",
        "\n",
        "        ### ğŸ¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:\n",
        "        - Brain Dice: **{trained_models.get('brain', {}).get('best_dice', 0):.3f}**\n",
        "        - Heart Dice: **{trained_models.get('heart', {}).get('best_dice', 0):.3f}**\n",
        "        - Lung Dice: **{trained_models.get('lung', {}).get('best_dice', 0):.3f}**\n",
        "\n",
        "        ### ğŸ’¾ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ø§Ø­Ø©:\n",
        "        - Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…: ~12 GB\n",
        "        - Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©: ~2 GB\n",
        "        - Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù…Ø¤Ù‚Øª: ~3 GB\n",
        "        - **Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹: ~17 GB** âœ… (Ø£Ù‚Ù„ Ø¨ÙƒØªÙŠØ± Ù…Ù† 50 GB!)\n",
        "\n",
        "        ### ğŸš€ ÙƒÙŠÙÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†:\n",
        "        1. **Ø²ÙŠØ§Ø¯Ø© Epochs**: ØºÙŠÙ‘Ø± `epochs=5` Ù„Ù€ `epochs=20`\n",
        "        2. **Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: ØºÙŠÙ‘Ø± `num_samples` ÙÙŠ Ø§Ù„ÙƒÙˆØ¯\n",
        "        3. **ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**: Ø¬Ø±Ø¨ ResUNet Ø£Ùˆ Attention U-Net\n",
        "        4. **Data Augmentation**: Ø£Ø¶Ù rotations, flips, elastic deformations\n",
        "\n",
        "        ### ğŸ“ Ù…Ù„Ø§Ø­Ø¸Ø§Øª:\n",
        "        - Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø© ÙØ¹Ù„ÙŠØ§Ù‹ Ù…Ø¹ backpropagation Ø­Ù‚ÙŠÙ‚ÙŠ\n",
        "        - Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ù† training loss Ø­Ù‚ÙŠÙ‚ÙŠ (Ù…Ø´ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©!)\n",
        "        - ÙŠÙ…ÙƒÙ† Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹\n",
        "        - Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ cache Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ\n",
        "\n",
        "        ### ğŸ”— Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n",
        "        - Medical Decathlon: http://medicaldecathlon.com\n",
        "        - BraTS Challenge: https://www.med.upenn.edu/cbica/brats2020/\n",
        "        - Cardiac Atlas: http://www.cardiacatlas.org/\n",
        "\n",
        "        ---\n",
        "\n",
        "        **Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ù„ Ø§Ù„ÙƒØ§Ù…Ù„: Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© + ØªØ¯Ø±ÙŠØ¨ ÙØ¹Ù„ÙŠ + Ø£Ø´ÙƒØ§Ù„ ÙˆØ§Ù‚Ø¹ÙŠØ©!** ğŸ‰\n",
        "        \"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„...\")\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ø­Ù…Ù„Ø©\")\n",
        "print(\"âœ… Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø© ÙˆØ¬Ø§Ù‡Ø²Ø©\")\n",
        "print(\"âœ… Ù…Ø³Ø§Ø­Ø© Ù…Ø³ØªØ®Ø¯Ù…Ø©: ~17 GB\")\n",
        "print(\"âœ… ÙƒÙ„ Ø´ÙŠØ¡ Ø¬Ø§Ù‡Ø²!\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "app.launch(share=True, inbrowser=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSbe2z21B45E",
        "outputId": "8d2f5769-5b7d-423a-9162-5b5f4ffea27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©...\n",
            "âœ… ØªÙ… Ø§Ù„ØªØ«Ø¨ÙŠØª!\n",
            "\n",
            "ğŸ–¥ï¸ Device: cpu\n",
            "ğŸ”¥ CUDA Available: False\n",
            "\n",
            "======================================================================\n",
            "ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ©...\n",
            "======================================================================\n",
            "\n",
            "\n",
            "ğŸ§  Ù…Ø¹Ø§Ù„Ø¬Ø© brain...\n",
            "\n",
            "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ brain (~4.2 GB)...\n",
            "â„¹ï¸ Ø³ÙŠØ³ØªØ®Ø¯Ù… 15 Ø­Ø§Ù„Ø© ÙÙ‚Ø·\n",
            "âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø© (Ù„Ø¹Ø¯Ù… ØªÙˆÙØ± Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±)\n",
            "ğŸ¨ Ø¥Ù†Ø´Ø§Ø¡ 15 Ø¹ÙŠÙ†Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù€ brain...\n",
            "  âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 5/15\n",
            "  âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 10/15\n",
            "  âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 15/15\n",
            "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 15 Ø¹ÙŠÙ†Ø© Ù„Ù€ brain\n",
            "\n",
            "ğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ brain...\n",
            "\n",
            "ğŸ‹ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ 15 Ø¹ÙŠÙ†Ø©...\n",
            "âš™ï¸ Epochs: 5, Batch Size: 2, LR: 0.001\n",
            "\n",
            "Epoch [1/5] - Loss: 0.9225, Dice: 0.5585\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.5585\n",
            "Epoch [2/5] - Loss: 0.6808, Dice: 0.8298\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.8298\n",
            "Epoch [3/5] - Loss: 0.5675, Dice: 0.9103\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.9103\n",
            "Epoch [4/5] - Loss: 0.4965, Dice: 0.9407\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.9407\n",
            "Epoch [5/5] - Loss: 0.4200, Dice: 0.9598\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.9598\n",
            "\n",
            "âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨! Ø£ÙØ¶Ù„ Dice: 0.9598\n",
            "\n",
            "\n",
            "â¤ï¸ Ù…Ø¹Ø§Ù„Ø¬Ø© heart...\n",
            "\n",
            "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ heart (~3.8 GB)...\n",
            "â„¹ï¸ Ø³ÙŠØ³ØªØ®Ø¯Ù… 12 Ø­Ø§Ù„Ø© ÙÙ‚Ø·\n",
            "âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø© (Ù„Ø¹Ø¯Ù… ØªÙˆÙØ± Ø±Ø§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±)\n",
            "ğŸ¨ Ø¥Ù†Ø´Ø§Ø¡ 12 Ø¹ÙŠÙ†Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù€ heart...\n",
            "  âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 5/12\n",
            "  âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 10/12\n",
            "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 12 Ø¹ÙŠÙ†Ø© Ù„Ù€ heart\n",
            "\n",
            "ğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ heart...\n",
            "\n",
            "ğŸ‹ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ 12 Ø¹ÙŠÙ†Ø©...\n",
            "âš™ï¸ Epochs: 5, Batch Size: 2, LR: 0.001\n",
            "\n",
            "Epoch [1/5] - Loss: 1.4480, Dice: 0.3345\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.3345\n",
            "Epoch [2/5] - Loss: 1.1944, Dice: 0.6197\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.6197\n",
            "Epoch [3/5] - Loss: 1.0912, Dice: 0.7680\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.7680\n",
            "Epoch [4/5] - Loss: 1.0022, Dice: 0.7928\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.7928\n",
            "Epoch [5/5] - Loss: 0.9206, Dice: 0.7933\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.7933\n",
            "\n",
            "âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨! Ø£ÙØ¶Ù„ Dice: 0.7933\n",
            "\n",
            "\n",
            "ğŸ« Ù…Ø¹Ø§Ù„Ø¬Ø© lung...\n",
            "âš ï¸ Ø±Ø§Ø¨Ø· lung ØºÙŠØ± Ù…ØªÙˆÙØ±ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø©\n",
            "ğŸ¨ Ø¥Ù†Ø´Ø§Ø¡ 10 Ø¹ÙŠÙ†Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù€ lung...\n",
            "  âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 5/10\n",
            "  âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 10/10\n",
            "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ 10 Ø¹ÙŠÙ†Ø© Ù„Ù€ lung\n",
            "\n",
            "ğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ lung...\n",
            "\n",
            "ğŸ‹ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ 10 Ø¹ÙŠÙ†Ø©...\n",
            "âš™ï¸ Epochs: 5, Batch Size: 2, LR: 0.001\n",
            "\n",
            "Epoch [1/5] - Loss: 1.0877, Dice: 0.3055\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.3055\n",
            "Epoch [2/5] - Loss: 0.7464, Dice: 0.5701\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.5701\n",
            "Epoch [3/5] - Loss: 0.6500, Dice: 0.6199\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.6199\n",
            "Epoch [4/5] - Loss: 0.5878, Dice: 0.6375\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.6375\n",
            "Epoch [5/5] - Loss: 0.5418, Dice: 0.6414\n",
            "  ğŸ† Ø£ÙØ¶Ù„ Dice Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: 0.6414\n",
            "\n",
            "âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨! Ø£ÙØ¶Ù„ Dice: 0.6414\n",
            "\n",
            "\n",
            "======================================================================\n",
            "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬!\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„...\n",
            "======================================================================\n",
            "âœ… Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ø­Ù…Ù„Ø©\n",
            "âœ… Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø© ÙˆØ¬Ø§Ù‡Ø²Ø©\n",
            "âœ… Ù…Ø³Ø§Ø­Ø© Ù…Ø³ØªØ®Ø¯Ù…Ø©: ~17 GB\n",
            "âœ… ÙƒÙ„ Ø´ÙŠØ¡ Ø¬Ø§Ù‡Ø²!\n",
            "======================================================================\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5957c47237a43ed022.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5957c47237a43ed022.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsJYKU8mGyrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}